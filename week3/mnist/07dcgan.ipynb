{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6020 on context None\n",
      "Mapped name None to device cuda0: Graphics Device (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "#import lasagne.layers.dnn\n",
    "\n",
    "import Dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_dataset():\n",
    "    import gzip\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        return data\n",
    "\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch iterator\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "def main():\n",
    "    \n",
    "    # Hyper Params\n",
    "    num_epochs = 100\n",
    "    batchsize = 128\n",
    "    initial_eta = 0.0002\n",
    "    \n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "       \n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    noiseVar = T.matrix('noise')\n",
    "    inputVar = T.tensor4('inputs')\n",
    "\n",
    "    # Build Network\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    generator = Dcgan.buildGenerator(noiseVar)\n",
    "    discriminator = Dcgan.buildDiscriminator(inputVar)\n",
    "\n",
    "    # Output expressions\n",
    "    realOut = lasagne.layers.get_output(discriminator)\n",
    "    fakeOut = lasagne.layers.get_output(discriminator,\n",
    "            lasagne.layers.get_output(generator))\n",
    "    \n",
    "    # Loss expressions\n",
    "    generatorLoss = lasagne.objectives.binary_crossentropy(\n",
    "                fakeOut, 1).mean()\n",
    "    discriminatorLoss = (lasagne.objectives.binary_crossentropy(\n",
    "                    realOut, 1)\n",
    "                    + lasagne.objectives.binary_crossentropy(\n",
    "                    fakeOut, 0)).mean()\n",
    "\n",
    "    # Update expressions \n",
    "    learning_rate = theano.shared(lasagne.utils.floatX(initial_eta))\n",
    "    generatorParams = lasagne.layers.get_all_params(generator, \n",
    "                trainable=True)\n",
    "    discriminatorParams = lasagne.layers.get_all_params(discriminator, \n",
    "                trainable=True)\n",
    "    updates = lasagne.updates.adam(generatorLoss, \n",
    "        generatorParams, \n",
    "        learning_rate, \n",
    "        beta1=0.5)\n",
    "    updates.update(lasagne.updates.adam(discriminatorLoss, \n",
    "        discriminatorParams, \n",
    "        learning_rate, \n",
    "        beta1=0.5))\n",
    "\n",
    "    # Train Function\n",
    "    train_fn = theano.function([noiseVar, inputVar], \n",
    "            [(realOut > .5).mean(),(fakeOut < .5).mean()], \n",
    "            updates=updates)\n",
    "\n",
    "    # Data generating function\n",
    "    gen_fn = theano.function([noiseVar],\n",
    "        lasagne.layers.get_output(generator,\n",
    "        deterministic=True))\n",
    "    \n",
    "    # Model Load if resumable\n",
    "    with np.load('mnist_gen.npz') as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    lasagne.layers.set_all_param_values(generator, param_values)\n",
    "    with np.load('mnist_disc.npz') as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    lasagne.layers.set_all_param_values(discriminator, param_values)\n",
    "    \n",
    "    # Training Loop\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batchsize, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            noise = lasagne.utils.floatX(np.random.rand(len(inputs), 100))\n",
    "\n",
    "            train_err += np.array(train_fn(noise, inputs))\n",
    "            train_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{}\".format(train_err / train_batches))\n",
    "        \n",
    "        \n",
    "        # And finally, we plot some generated data\n",
    "        samples = gen_fn(lasagne.utils.floatX(np.random.rand(42, 100)))\n",
    "\n",
    "        plt.imsave('mnist_samples.png',\n",
    "                       (samples.reshape(6, 7, 28, 28)\n",
    "                               .transpose(0, 2, 1, 3)\n",
    "                               .reshape(6*28, 7*28)),\n",
    "                       cmap='gray')\n",
    "            \n",
    "    # Save model\n",
    "    np.savez('mnist_gen.npz', *lasagne.layers.get_all_param_values(generator))\n",
    "    np.savez('mnist_disc.npz', *lasagne.layers.get_all_param_values(discriminator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Generator output: (None, 1, 28, 28)\n",
      "num params 4918532\n",
      "Discriminator output: (None, 1)\n",
      "num params 3268769\n",
      "Starting training...\n",
      "Epoch 1 of 100 took 4.921s\n",
      "  training loss:\t\t[ 0.98932292  0.98798077]\n",
      "Epoch 2 of 100 took 4.875s\n",
      "  training loss:\t\t[ 0.99076522  0.98980369]\n",
      "Epoch 3 of 100 took 4.993s\n",
      "  training loss:\t\t[ 0.99485176  0.99356971]\n",
      "Epoch 4 of 100 took 4.890s\n",
      "  training loss:\t\t[ 0.98010817  0.97800481]\n",
      "Epoch 5 of 100 took 5.039s\n",
      "  training loss:\t\t[ 0.98946314  0.98625801]\n",
      "Epoch 6 of 100 took 4.927s\n",
      "  training loss:\t\t[ 0.99811699  0.99723558]\n",
      "Epoch 7 of 100 took 5.036s\n",
      "  training loss:\t\t[ 0.99066506  0.98928285]\n",
      "Epoch 8 of 100 took 4.907s\n",
      "  training loss:\t\t[ 0.98369391  0.98209135]\n",
      "Epoch 9 of 100 took 4.934s\n",
      "  training loss:\t\t[ 0.99625401  0.99523237]\n",
      "Epoch 10 of 100 took 4.934s\n",
      "  training loss:\t\t[ 0.98966346  0.98774038]\n",
      "Epoch 11 of 100 took 5.039s\n",
      "  training loss:\t\t[ 0.98167067  0.98004808]\n",
      "Epoch 12 of 100 took 5.032s\n",
      "  training loss:\t\t[ 0.99781651  0.99671474]\n",
      "Epoch 13 of 100 took 5.240s\n",
      "  training loss:\t\t[ 0.99300881  0.99178686]\n",
      "Epoch 14 of 100 took 5.449s\n",
      "  training loss:\t\t[ 0.98719952  0.98641827]\n",
      "Epoch 15 of 100 took 5.460s\n",
      "  training loss:\t\t[ 0.99387019  0.99244792]\n",
      "Epoch 16 of 100 took 5.428s\n",
      "  training loss:\t\t[ 0.98519631  0.98313301]\n",
      "Epoch 17 of 100 took 5.469s\n",
      "  training loss:\t\t[ 0.99707532  0.9953726 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-12bdfa773fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-1dfe5982d849>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "        main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}