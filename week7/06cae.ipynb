{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 750 Ti (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "#import lasagne.layers.dnn\n",
    "\n",
    "import Cae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def im2ar(x):\n",
    "    y = [[[0]*len(x)]*len(x)]*3\n",
    "    y[0] = x[:,:,0]\n",
    "    y[1] = x[:,:,1]\n",
    "    y[2] = x[:,:,2]\n",
    "    return y\n",
    "\n",
    "def ar2im(x):\n",
    "    y = [[[0]*3]*len(x)]*len(x)\n",
    "    y[:,:,0] = x[0,:,:] \n",
    "    y[:,:,1] = x[1,:,:]\n",
    "    y[:,:,2] = x[2,:,:]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_dataset_mscoco():\n",
    "    #Path\n",
    "    mscoco=\"/home/myuser/Documents/Lasagne/inpainting\"\n",
    "    split=\"train2014\"\n",
    "    data_path = os.path.join(mscoco, split)\n",
    "    imgs = glob.glob(data_path + \"/*.jpg\")\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "            \n",
    "    for i, img_path in enumerate(imgs):\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.divide(np.array(img,dtype='float32'),255)\n",
    "\n",
    "        if len(img_array.shape) == 3:\n",
    "            temp = np.copy(img_array)\n",
    "            input = np.copy(img_array)\n",
    "            input[16:48, 16:48,:] = 0\n",
    "            target = img_array[16:48, 16:48,:]\n",
    "        else:\n",
    "            input[:,:,0] = np.copy(img_array)\n",
    "            input[:,:,1] = np.copy(img_array)\n",
    "            input[:,:,2] = np.copy(img_array)\n",
    "            target = input[16:48, 16:48,:]\n",
    "            input[16:48, 16:48,:] = 0\n",
    "        \n",
    "        X_train.append(im2ar(input))\n",
    "        y_train.append(im2ar(target))\n",
    "    \n",
    "    split=\"val2014\"\n",
    "    data_path = os.path.join(mscoco, split)\n",
    "    imgs = glob.glob(data_path + \"/*.jpg\")\n",
    "    \n",
    "    X_val = []\n",
    "    y_val = []\n",
    "            \n",
    "    for i, img_path in enumerate(imgs):\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.divide(np.array(img,dtype='float32'),255)\n",
    "\n",
    "        if len(img_array.shape) == 3:\n",
    "            input = np.copy(img_array)\n",
    "            input[16:48, 16:48,:] = 0\n",
    "            target = img_array[16:48, 16:48,:]\n",
    "        else:\n",
    "            input[:,:,0] = np.copy(img_array)\n",
    "            input[:,:,1] = np.copy(img_array)\n",
    "            input[:,:,2] = np.copy(img_array)\n",
    "            target = input[16:48, 16:48,:]\n",
    "            input[16:48, 16:48,:] = 0\n",
    "        \n",
    "        X_val.append(im2ar(input))\n",
    "        y_val.append(im2ar(target))\n",
    "    \n",
    "    # We reserve the last 10000 training examples for testing.\n",
    "    X_val, X_test = X_val[:-10000], X_val[-10000:]\n",
    "    y_val, y_test = y_val[:-10000], y_val[-10000:]\n",
    "    \n",
    "    return (np.array(X_train),np.array(y_train),np.array(X_val),np.array(y_val),np.array(X_test),np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Batch iterator\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "def main():\n",
    "    \n",
    "    # Hyper Params\n",
    "    num_epochs = 600\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.9\n",
    "    batchsize = 128\n",
    "    \n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset_mscoco()\n",
    "    \n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    inputVar = T.tensor4('inputs')\n",
    "    target_var = T.tensor4('targets')\n",
    "\n",
    "    # Build Network\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    network = Cae.build(inputVar)\n",
    "    \n",
    "    #Load model\n",
    "    with np.load('cae-400e.npz') as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    lasagne.layers.set_all_param_values(network, param_values)\n",
    "    \n",
    "    # Training Loss expression\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    # Add regularization lasagne.regularization.\n",
    "\n",
    "    # Update expressions \n",
    "    # Stochastic Gradient Descent (SGD) with Nesterov momentum\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate, momentum)\n",
    "\n",
    "    # Test Loss expression\n",
    "    # 'Deterministic = True' disables droupout\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.squared_error(test_prediction,target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "\n",
    "    # Train Function\n",
    "    train_fn = theano.function([inputVar, target_var], loss, updates=updates)\n",
    "\n",
    "    # Test Function\n",
    "    val_fn = theano.function([inputVar, target_var], test_loss)\n",
    "    # Training Loop\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batchsize, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # Full pass over the validation data\n",
    "        val_err = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, batchsize, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_batches += 1\n",
    "\n",
    "        # Print the results for this epoch\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "\n",
    "    # Print the test error\n",
    "    test_err = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, batchsize, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "\n",
    "\n",
    "    # Save model\n",
    "    np.savez('cae-1000e.npz', *lasagne.layers.get_all_param_values(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Network output: (None, 16, 56, 56)\n",
      "Network output: (None, 16, 28, 28)\n",
      "Network output: (None, 16, 26, 26)\n",
      "Network output: (None, 16, 13, 13)\n",
      "Network output: (None, 16, 14, 14)\n",
      "Network output: (None, 16, 28, 28)\n",
      "Network output: (None, 3, 32, 32)\n",
      "network params 11973059\n",
      "Starting training...\n",
      "Epoch 1 of 600 took 76.136s\n",
      "  training loss:\t\t0.039457\n",
      "  validation loss:\t\t0.036741\n",
      "Epoch 2 of 600 took 76.060s\n",
      "  training loss:\t\t0.039436\n",
      "  validation loss:\t\t0.036775\n",
      "Epoch 3 of 600 took 77.182s\n",
      "  training loss:\t\t0.039417\n",
      "  validation loss:\t\t0.036664\n",
      "Epoch 4 of 600 took 80.042s\n",
      "  training loss:\t\t0.039440\n",
      "  validation loss:\t\t0.036819\n",
      "Epoch 5 of 600 took 77.078s\n",
      "  training loss:\t\t0.039431\n",
      "  validation loss:\t\t0.036721\n",
      "Epoch 6 of 600 took 77.611s\n",
      "  training loss:\t\t0.039453\n",
      "  validation loss:\t\t0.036684\n",
      "Epoch 7 of 600 took 81.774s\n",
      "  training loss:\t\t0.039447\n",
      "  validation loss:\t\t0.036495\n",
      "Epoch 8 of 600 took 83.818s\n",
      "  training loss:\t\t0.039427\n",
      "  validation loss:\t\t0.036551\n",
      "Epoch 9 of 600 took 83.285s\n",
      "  training loss:\t\t0.039415\n",
      "  validation loss:\t\t0.036695\n",
      "Epoch 10 of 600 took 81.862s\n",
      "  training loss:\t\t0.039411\n",
      "  validation loss:\t\t0.036755\n",
      "Epoch 11 of 600 took 81.930s\n",
      "  training loss:\t\t0.039399\n",
      "  validation loss:\t\t0.036720\n",
      "Epoch 12 of 600 took 82.455s\n",
      "  training loss:\t\t0.039416\n",
      "  validation loss:\t\t0.036492\n",
      "Epoch 13 of 600 took 82.025s\n",
      "  training loss:\t\t0.039414\n",
      "  validation loss:\t\t0.036636\n",
      "Epoch 14 of 600 took 82.049s\n",
      "  training loss:\t\t0.039408\n",
      "  validation loss:\t\t0.036649\n",
      "Epoch 15 of 600 took 82.065s\n",
      "  training loss:\t\t0.039360\n",
      "  validation loss:\t\t0.036862\n",
      "Epoch 16 of 600 took 82.089s\n",
      "  training loss:\t\t0.039394\n",
      "  validation loss:\t\t0.036739\n",
      "Epoch 17 of 600 took 82.418s\n",
      "  training loss:\t\t0.039358\n",
      "  validation loss:\t\t0.036657\n",
      "Epoch 18 of 600 took 82.121s\n",
      "  training loss:\t\t0.039391\n",
      "  validation loss:\t\t0.036697\n",
      "Epoch 19 of 600 took 80.873s\n",
      "  training loss:\t\t0.039370\n",
      "  validation loss:\t\t0.036878\n",
      "Epoch 20 of 600 took 80.006s\n",
      "  training loss:\t\t0.039378\n",
      "  validation loss:\t\t0.036657\n",
      "Epoch 21 of 600 took 80.050s\n",
      "  training loss:\t\t0.039394\n",
      "  validation loss:\t\t0.036629\n",
      "Epoch 22 of 600 took 79.993s\n",
      "  training loss:\t\t0.039385\n",
      "  validation loss:\t\t0.036777\n",
      "Epoch 23 of 600 took 79.966s\n",
      "  training loss:\t\t0.039344\n",
      "  validation loss:\t\t0.036582\n",
      "Epoch 24 of 600 took 80.935s\n",
      "  training loss:\t\t0.039333\n",
      "  validation loss:\t\t0.036555\n",
      "Epoch 25 of 600 took 82.254s\n",
      "  training loss:\t\t0.039340\n",
      "  validation loss:\t\t0.036710\n",
      "Epoch 26 of 600 took 82.110s\n",
      "  training loss:\t\t0.039350\n",
      "  validation loss:\t\t0.036507\n",
      "Epoch 27 of 600 took 82.207s\n",
      "  training loss:\t\t0.039377\n",
      "  validation loss:\t\t0.036516\n",
      "Epoch 28 of 600 took 82.148s\n",
      "  training loss:\t\t0.039338\n",
      "  validation loss:\t\t0.036970\n",
      "Epoch 29 of 600 took 82.089s\n",
      "  training loss:\t\t0.039328\n",
      "  validation loss:\t\t0.036588\n",
      "Epoch 30 of 600 took 79.663s\n",
      "  training loss:\t\t0.039316\n",
      "  validation loss:\t\t0.036597\n",
      "Epoch 31 of 600 took 81.047s\n",
      "  training loss:\t\t0.039335\n",
      "  validation loss:\t\t0.036555\n",
      "Epoch 32 of 600 took 82.334s\n",
      "  training loss:\t\t0.039341\n",
      "  validation loss:\t\t0.036550\n",
      "Epoch 33 of 600 took 82.285s\n",
      "  training loss:\t\t0.039315\n",
      "  validation loss:\t\t0.036598\n",
      "Epoch 34 of 600 took 80.246s\n",
      "  training loss:\t\t0.039277\n",
      "  validation loss:\t\t0.036514\n",
      "Epoch 35 of 600 took 79.772s\n",
      "  training loss:\t\t0.039305\n",
      "  validation loss:\t\t0.036578\n",
      "Epoch 36 of 600 took 79.791s\n",
      "  training loss:\t\t0.039300\n",
      "  validation loss:\t\t0.036521\n",
      "Epoch 37 of 600 took 79.860s\n",
      "  training loss:\t\t0.039301\n",
      "  validation loss:\t\t0.036614\n",
      "Epoch 38 of 600 took 79.788s\n",
      "  training loss:\t\t0.039282\n",
      "  validation loss:\t\t0.036581\n",
      "Epoch 39 of 600 took 79.726s\n",
      "  training loss:\t\t0.039270\n",
      "  validation loss:\t\t0.036802\n",
      "Epoch 40 of 600 took 79.950s\n",
      "  training loss:\t\t0.039285\n",
      "  validation loss:\t\t0.036674\n",
      "Epoch 41 of 600 took 79.997s\n",
      "  training loss:\t\t0.039276\n",
      "  validation loss:\t\t0.036621\n",
      "Epoch 42 of 600 took 79.860s\n",
      "  training loss:\t\t0.039269\n",
      "  validation loss:\t\t0.036769\n",
      "Epoch 43 of 600 took 79.886s\n",
      "  training loss:\t\t0.039264\n",
      "  validation loss:\t\t0.036420\n",
      "Epoch 44 of 600 took 79.980s\n",
      "  training loss:\t\t0.039267\n",
      "  validation loss:\t\t0.036632\n",
      "Epoch 45 of 600 took 79.987s\n",
      "  training loss:\t\t0.039240\n",
      "  validation loss:\t\t0.036426\n",
      "Epoch 46 of 600 took 79.926s\n",
      "  training loss:\t\t0.039257\n",
      "  validation loss:\t\t0.036650\n",
      "Epoch 47 of 600 took 79.771s\n",
      "  training loss:\t\t0.039262\n",
      "  validation loss:\t\t0.036339\n",
      "Epoch 48 of 600 took 79.829s\n",
      "  training loss:\t\t0.039269\n",
      "  validation loss:\t\t0.036509\n",
      "Epoch 49 of 600 took 79.887s\n",
      "  training loss:\t\t0.039246\n",
      "  validation loss:\t\t0.036567\n",
      "Epoch 50 of 600 took 79.894s\n",
      "  training loss:\t\t0.039245\n",
      "  validation loss:\t\t0.036559\n",
      "Epoch 51 of 600 took 79.774s\n",
      "  training loss:\t\t0.039243\n",
      "  validation loss:\t\t0.036557\n",
      "Epoch 52 of 600 took 79.877s\n",
      "  training loss:\t\t0.039237\n",
      "  validation loss:\t\t0.036385\n",
      "Epoch 53 of 600 took 79.854s\n",
      "  training loss:\t\t0.039231\n",
      "  validation loss:\t\t0.036566\n",
      "Epoch 54 of 600 took 79.975s\n",
      "  training loss:\t\t0.039250\n",
      "  validation loss:\t\t0.036579\n",
      "Epoch 55 of 600 took 79.879s\n",
      "  training loss:\t\t0.039206\n",
      "  validation loss:\t\t0.036644\n",
      "Epoch 56 of 600 took 79.832s\n",
      "  training loss:\t\t0.039212\n",
      "  validation loss:\t\t0.036621\n",
      "Epoch 57 of 600 took 79.849s\n",
      "  training loss:\t\t0.039196\n",
      "  validation loss:\t\t0.036530\n",
      "Epoch 58 of 600 took 79.915s\n",
      "  training loss:\t\t0.039212\n",
      "  validation loss:\t\t0.036781\n",
      "Epoch 59 of 600 took 79.967s\n",
      "  training loss:\t\t0.039190\n",
      "  validation loss:\t\t0.036489\n",
      "Epoch 60 of 600 took 80.125s\n",
      "  training loss:\t\t0.039181\n",
      "  validation loss:\t\t0.036489\n",
      "Epoch 61 of 600 took 79.845s\n",
      "  training loss:\t\t0.039200\n",
      "  validation loss:\t\t0.036630\n",
      "Epoch 62 of 600 took 79.825s\n",
      "  training loss:\t\t0.039180\n",
      "  validation loss:\t\t0.036537\n",
      "Epoch 63 of 600 took 79.802s\n",
      "  training loss:\t\t0.039200\n",
      "  validation loss:\t\t0.036510\n",
      "Epoch 64 of 600 took 79.867s\n",
      "  training loss:\t\t0.039180\n",
      "  validation loss:\t\t0.036459\n",
      "Epoch 65 of 600 took 79.955s\n",
      "  training loss:\t\t0.039204\n",
      "  validation loss:\t\t0.036588\n",
      "Epoch 66 of 600 took 79.966s\n",
      "  training loss:\t\t0.039208\n",
      "  validation loss:\t\t0.036651\n",
      "Epoch 67 of 600 took 80.033s\n",
      "  training loss:\t\t0.039175\n",
      "  validation loss:\t\t0.036605\n",
      "Epoch 68 of 600 took 79.910s\n",
      "  training loss:\t\t0.039189\n",
      "  validation loss:\t\t0.036507\n",
      "Epoch 69 of 600 took 79.808s\n",
      "  training loss:\t\t0.039158\n",
      "  validation loss:\t\t0.036510\n",
      "Epoch 70 of 600 took 79.713s\n",
      "  training loss:\t\t0.039171\n",
      "  validation loss:\t\t0.036775\n",
      "Epoch 71 of 600 took 79.799s\n",
      "  training loss:\t\t0.039163\n",
      "  validation loss:\t\t0.036610\n",
      "Epoch 72 of 600 took 79.923s\n",
      "  training loss:\t\t0.039154\n",
      "  validation loss:\t\t0.036443\n",
      "Epoch 73 of 600 took 79.807s\n",
      "  training loss:\t\t0.039171\n",
      "  validation loss:\t\t0.036492\n",
      "Epoch 74 of 600 took 76.538s\n",
      "  training loss:\t\t0.039151\n",
      "  validation loss:\t\t0.036308\n",
      "Epoch 75 of 600 took 71.532s\n",
      "  training loss:\t\t0.039141\n",
      "  validation loss:\t\t0.036334\n",
      "Epoch 76 of 600 took 71.492s\n",
      "  training loss:\t\t0.039155\n",
      "  validation loss:\t\t0.036411\n",
      "Epoch 77 of 600 took 71.457s\n",
      "  training loss:\t\t0.039129\n",
      "  validation loss:\t\t0.036502\n",
      "Epoch 78 of 600 took 71.527s\n",
      "  training loss:\t\t0.039145\n",
      "  validation loss:\t\t0.036395\n",
      "Epoch 79 of 600 took 71.488s\n",
      "  training loss:\t\t0.039131\n",
      "  validation loss:\t\t0.036554\n",
      "Epoch 80 of 600 took 71.467s\n",
      "  training loss:\t\t0.039109\n",
      "  validation loss:\t\t0.036503\n",
      "Epoch 81 of 600 took 71.490s\n",
      "  training loss:\t\t0.039133\n",
      "  validation loss:\t\t0.036413\n",
      "Epoch 82 of 600 took 71.517s\n",
      "  training loss:\t\t0.039126\n",
      "  validation loss:\t\t0.036564\n",
      "Epoch 83 of 600 took 71.526s\n",
      "  training loss:\t\t0.039116\n",
      "  validation loss:\t\t0.036343\n",
      "Epoch 84 of 600 took 71.510s\n",
      "  training loss:\t\t0.039109\n",
      "  validation loss:\t\t0.036470\n",
      "Epoch 85 of 600 took 71.478s\n",
      "  training loss:\t\t0.039120\n",
      "  validation loss:\t\t0.036476\n",
      "Epoch 86 of 600 took 71.553s\n",
      "  training loss:\t\t0.039096\n",
      "  validation loss:\t\t0.036477\n",
      "Epoch 87 of 600 took 71.622s\n",
      "  training loss:\t\t0.039117\n",
      "  validation loss:\t\t0.036396\n",
      "Epoch 88 of 600 took 71.500s\n",
      "  training loss:\t\t0.039094\n",
      "  validation loss:\t\t0.036318\n",
      "Epoch 89 of 600 took 71.519s\n",
      "  training loss:\t\t0.039075\n",
      "  validation loss:\t\t0.036424\n",
      "Epoch 90 of 600 took 71.482s\n",
      "  training loss:\t\t0.039086\n",
      "  validation loss:\t\t0.036405\n",
      "Epoch 91 of 600 took 71.464s\n",
      "  training loss:\t\t0.039073\n",
      "  validation loss:\t\t0.036399\n",
      "Epoch 92 of 600 took 71.479s\n",
      "  training loss:\t\t0.039085\n",
      "  validation loss:\t\t0.036342\n",
      "Epoch 93 of 600 took 71.516s\n",
      "  training loss:\t\t0.039086\n",
      "  validation loss:\t\t0.036482\n",
      "Epoch 94 of 600 took 71.451s\n",
      "  training loss:\t\t0.039062\n",
      "  validation loss:\t\t0.036416\n",
      "Epoch 95 of 600 took 71.494s\n",
      "  training loss:\t\t0.039062\n",
      "  validation loss:\t\t0.036510\n",
      "Epoch 96 of 600 took 74.542s\n",
      "  training loss:\t\t0.039064\n",
      "  validation loss:\t\t0.036311\n",
      "Epoch 97 of 600 took 78.629s\n",
      "  training loss:\t\t0.039050\n",
      "  validation loss:\t\t0.036235\n",
      "Epoch 98 of 600 took 76.731s\n",
      "  training loss:\t\t0.039078\n",
      "  validation loss:\t\t0.036352\n",
      "Epoch 99 of 600 took 77.717s\n",
      "  training loss:\t\t0.039063\n",
      "  validation loss:\t\t0.036330\n",
      "Epoch 100 of 600 took 76.704s\n",
      "  training loss:\t\t0.039038\n",
      "  validation loss:\t\t0.036473\n",
      "Epoch 101 of 600 took 76.769s\n",
      "  training loss:\t\t0.039058\n",
      "  validation loss:\t\t0.036596\n",
      "Epoch 102 of 600 took 79.331s\n",
      "  training loss:\t\t0.039050\n",
      "  validation loss:\t\t0.036274\n",
      "Epoch 103 of 600 took 81.234s\n",
      "  training loss:\t\t0.039042\n",
      "  validation loss:\t\t0.036524\n",
      "Epoch 104 of 600 took 81.199s\n",
      "  training loss:\t\t0.039053\n",
      "  validation loss:\t\t0.036380\n",
      "Epoch 105 of 600 took 81.306s\n",
      "  training loss:\t\t0.039056\n",
      "  validation loss:\t\t0.036472\n",
      "Epoch 106 of 600 took 81.345s\n",
      "  training loss:\t\t0.039015\n",
      "  validation loss:\t\t0.036375\n",
      "Epoch 107 of 600 took 81.318s\n",
      "  training loss:\t\t0.039019\n",
      "  validation loss:\t\t0.036339\n",
      "Epoch 108 of 600 took 81.315s\n",
      "  training loss:\t\t0.039021\n",
      "  validation loss:\t\t0.036423\n",
      "Epoch 109 of 600 took 81.476s\n",
      "  training loss:\t\t0.039016\n",
      "  validation loss:\t\t0.036316\n",
      "Epoch 110 of 600 took 81.382s\n",
      "  training loss:\t\t0.039018\n",
      "  validation loss:\t\t0.036271\n",
      "Epoch 111 of 600 took 81.291s\n",
      "  training loss:\t\t0.039006\n",
      "  validation loss:\t\t0.036597\n",
      "Epoch 112 of 600 took 81.194s\n",
      "  training loss:\t\t0.038998\n",
      "  validation loss:\t\t0.036382\n",
      "Epoch 113 of 600 took 81.294s\n",
      "  training loss:\t\t0.039017\n",
      "  validation loss:\t\t0.036310\n",
      "Epoch 114 of 600 took 81.383s\n",
      "  training loss:\t\t0.038983\n",
      "  validation loss:\t\t0.036285\n",
      "Epoch 115 of 600 took 81.299s\n",
      "  training loss:\t\t0.038998\n",
      "  validation loss:\t\t0.036439\n",
      "Epoch 116 of 600 took 81.382s\n",
      "  training loss:\t\t0.038992\n",
      "  validation loss:\t\t0.036452\n",
      "Epoch 117 of 600 took 79.358s\n",
      "  training loss:\t\t0.039020\n",
      "  validation loss:\t\t0.036504\n",
      "Epoch 118 of 600 took 74.018s\n",
      "  training loss:\t\t0.038989\n",
      "  validation loss:\t\t0.036341\n",
      "Epoch 119 of 600 took 74.002s\n",
      "  training loss:\t\t0.038978\n",
      "  validation loss:\t\t0.036323\n",
      "Epoch 120 of 600 took 74.043s\n",
      "  training loss:\t\t0.038988\n",
      "  validation loss:\t\t0.036313\n",
      "Epoch 121 of 600 took 74.113s\n",
      "  training loss:\t\t0.038974\n",
      "  validation loss:\t\t0.036483\n",
      "Epoch 122 of 600 took 73.376s\n",
      "  training loss:\t\t0.038962\n",
      "  validation loss:\t\t0.036323\n",
      "Epoch 123 of 600 took 71.049s\n",
      "  training loss:\t\t0.038973\n",
      "  validation loss:\t\t0.036470\n",
      "Epoch 124 of 600 took 71.121s\n",
      "  training loss:\t\t0.038958\n",
      "  validation loss:\t\t0.036525\n",
      "Epoch 125 of 600 took 71.089s\n",
      "  training loss:\t\t0.038937\n",
      "  validation loss:\t\t0.036230\n",
      "Epoch 126 of 600 took 71.114s\n",
      "  training loss:\t\t0.038942\n",
      "  validation loss:\t\t0.036468\n",
      "Epoch 127 of 600 took 71.065s\n",
      "  training loss:\t\t0.038955\n",
      "  validation loss:\t\t0.036238\n",
      "Epoch 128 of 600 took 71.085s\n",
      "  training loss:\t\t0.038932\n",
      "  validation loss:\t\t0.036255\n",
      "Epoch 129 of 600 took 71.095s\n",
      "  training loss:\t\t0.038943\n",
      "  validation loss:\t\t0.036375\n",
      "Epoch 130 of 600 took 71.146s\n",
      "  training loss:\t\t0.038950\n",
      "  validation loss:\t\t0.036415\n",
      "Epoch 131 of 600 took 71.086s\n",
      "  training loss:\t\t0.038947\n",
      "  validation loss:\t\t0.036407\n",
      "Epoch 132 of 600 took 71.127s\n",
      "  training loss:\t\t0.038934\n",
      "  validation loss:\t\t0.036315\n",
      "Epoch 133 of 600 took 71.081s\n",
      "  training loss:\t\t0.038930\n",
      "  validation loss:\t\t0.036380\n",
      "Epoch 134 of 600 took 71.086s\n",
      "  training loss:\t\t0.038934\n",
      "  validation loss:\t\t0.036455\n",
      "Epoch 135 of 600 took 71.146s\n",
      "  training loss:\t\t0.038918\n",
      "  validation loss:\t\t0.036355\n",
      "Epoch 136 of 600 took 71.102s\n",
      "  training loss:\t\t0.038919\n",
      "  validation loss:\t\t0.036395\n",
      "Epoch 137 of 600 took 71.090s\n",
      "  training loss:\t\t0.038921\n",
      "  validation loss:\t\t0.036393\n",
      "Epoch 138 of 600 took 71.088s\n",
      "  training loss:\t\t0.038905\n",
      "  validation loss:\t\t0.036500\n",
      "Epoch 139 of 600 took 71.111s\n",
      "  training loss:\t\t0.038909\n",
      "  validation loss:\t\t0.036542\n",
      "Epoch 140 of 600 took 71.099s\n",
      "  training loss:\t\t0.038911\n",
      "  validation loss:\t\t0.036192\n",
      "Epoch 141 of 600 took 71.037s\n",
      "  training loss:\t\t0.038913\n",
      "  validation loss:\t\t0.036254\n",
      "Epoch 142 of 600 took 71.062s\n",
      "  training loss:\t\t0.038928\n",
      "  validation loss:\t\t0.036257\n",
      "Epoch 143 of 600 took 71.088s\n",
      "  training loss:\t\t0.038922\n",
      "  validation loss:\t\t0.036229\n",
      "Epoch 144 of 600 took 71.108s\n",
      "  training loss:\t\t0.038894\n",
      "  validation loss:\t\t0.036125\n",
      "Epoch 145 of 600 took 71.087s\n",
      "  training loss:\t\t0.038875\n",
      "  validation loss:\t\t0.036388\n",
      "Epoch 146 of 600 took 71.081s\n",
      "  training loss:\t\t0.038879\n",
      "  validation loss:\t\t0.036229\n",
      "Epoch 147 of 600 took 71.139s\n",
      "  training loss:\t\t0.038864\n",
      "  validation loss:\t\t0.036140\n",
      "Epoch 148 of 600 took 71.079s\n",
      "  training loss:\t\t0.038865\n",
      "  validation loss:\t\t0.036289\n",
      "Epoch 149 of 600 took 71.099s\n",
      "  training loss:\t\t0.038885\n",
      "  validation loss:\t\t0.036414\n",
      "Epoch 150 of 600 took 71.106s\n",
      "  training loss:\t\t0.038882\n",
      "  validation loss:\t\t0.036349\n",
      "Epoch 151 of 600 took 71.147s\n",
      "  training loss:\t\t0.038870\n",
      "  validation loss:\t\t0.036172\n",
      "Epoch 152 of 600 took 71.102s\n",
      "  training loss:\t\t0.038881\n",
      "  validation loss:\t\t0.036258\n",
      "Epoch 153 of 600 took 71.084s\n",
      "  training loss:\t\t0.038854\n",
      "  validation loss:\t\t0.036316\n",
      "Epoch 154 of 600 took 71.101s\n",
      "  training loss:\t\t0.038851\n",
      "  validation loss:\t\t0.036376\n",
      "Epoch 155 of 600 took 71.073s\n",
      "  training loss:\t\t0.038876\n",
      "  validation loss:\t\t0.036564\n",
      "Epoch 156 of 600 took 71.154s\n",
      "  training loss:\t\t0.038865\n",
      "  validation loss:\t\t0.036330\n",
      "Epoch 157 of 600 took 71.062s\n",
      "  training loss:\t\t0.038843\n",
      "  validation loss:\t\t0.036450\n",
      "Epoch 158 of 600 took 71.065s\n",
      "  training loss:\t\t0.038851\n",
      "  validation loss:\t\t0.036361\n",
      "Epoch 159 of 600 took 71.065s\n",
      "  training loss:\t\t0.038841\n",
      "  validation loss:\t\t0.036292\n",
      "Epoch 160 of 600 took 71.068s\n",
      "  training loss:\t\t0.038841\n",
      "  validation loss:\t\t0.036303\n",
      "Epoch 161 of 600 took 71.075s\n",
      "  training loss:\t\t0.038837\n",
      "  validation loss:\t\t0.036246\n",
      "Epoch 162 of 600 took 71.069s\n",
      "  training loss:\t\t0.038827\n",
      "  validation loss:\t\t0.036378\n",
      "Epoch 163 of 600 took 71.054s\n",
      "  training loss:\t\t0.038828\n",
      "  validation loss:\t\t0.036324\n",
      "Epoch 164 of 600 took 71.161s\n",
      "  training loss:\t\t0.038823\n",
      "  validation loss:\t\t0.036271\n",
      "Epoch 165 of 600 took 71.081s\n",
      "  training loss:\t\t0.038813\n",
      "  validation loss:\t\t0.036194\n",
      "Epoch 166 of 600 took 71.108s\n",
      "  training loss:\t\t0.038817\n",
      "  validation loss:\t\t0.036234\n",
      "Epoch 167 of 600 took 71.080s\n",
      "  training loss:\t\t0.038825\n",
      "  validation loss:\t\t0.036217\n",
      "Epoch 168 of 600 took 71.086s\n",
      "  training loss:\t\t0.038822\n",
      "  validation loss:\t\t0.036213\n",
      "Epoch 169 of 600 took 71.125s\n",
      "  training loss:\t\t0.038792\n",
      "  validation loss:\t\t0.036429\n",
      "Epoch 170 of 600 took 71.087s\n",
      "  training loss:\t\t0.038819\n",
      "  validation loss:\t\t0.036152\n",
      "Epoch 171 of 600 took 71.097s\n",
      "  training loss:\t\t0.038807\n",
      "  validation loss:\t\t0.036187\n",
      "Epoch 172 of 600 took 71.150s\n",
      "  training loss:\t\t0.038807\n",
      "  validation loss:\t\t0.036177\n",
      "Epoch 173 of 600 took 71.182s\n",
      "  training loss:\t\t0.038824\n",
      "  validation loss:\t\t0.036351\n",
      "Epoch 174 of 600 took 71.084s\n",
      "  training loss:\t\t0.038800\n",
      "  validation loss:\t\t0.036245\n",
      "Epoch 175 of 600 took 71.098s\n",
      "  training loss:\t\t0.038792\n",
      "  validation loss:\t\t0.036261\n",
      "Epoch 176 of 600 took 71.064s\n",
      "  training loss:\t\t0.038787\n",
      "  validation loss:\t\t0.036308\n",
      "Epoch 177 of 600 took 71.067s\n",
      "  training loss:\t\t0.038774\n",
      "  validation loss:\t\t0.036513\n",
      "Epoch 178 of 600 took 71.148s\n",
      "  training loss:\t\t0.038761\n",
      "  validation loss:\t\t0.036142\n",
      "Epoch 179 of 600 took 71.071s\n",
      "  training loss:\t\t0.038772\n",
      "  validation loss:\t\t0.036322\n",
      "Epoch 180 of 600 took 71.064s\n",
      "  training loss:\t\t0.038761\n",
      "  validation loss:\t\t0.036290\n",
      "Epoch 181 of 600 took 71.133s\n",
      "  training loss:\t\t0.038771\n",
      "  validation loss:\t\t0.036172\n",
      "Epoch 182 of 600 took 71.060s\n",
      "  training loss:\t\t0.038754\n",
      "  validation loss:\t\t0.036180\n",
      "Epoch 183 of 600 took 71.072s\n",
      "  training loss:\t\t0.038770\n",
      "  validation loss:\t\t0.036250\n",
      "Epoch 184 of 600 took 71.091s\n",
      "  training loss:\t\t0.038782\n",
      "  validation loss:\t\t0.036191\n",
      "Epoch 185 of 600 took 71.079s\n",
      "  training loss:\t\t0.038750\n",
      "  validation loss:\t\t0.036299\n",
      "Epoch 186 of 600 took 71.102s\n",
      "  training loss:\t\t0.038760\n",
      "  validation loss:\t\t0.036329\n",
      "Epoch 187 of 600 took 71.086s\n",
      "  training loss:\t\t0.038730\n",
      "  validation loss:\t\t0.036256\n",
      "Epoch 188 of 600 took 71.090s\n",
      "  training loss:\t\t0.038728\n",
      "  validation loss:\t\t0.036195\n",
      "Epoch 189 of 600 took 71.100s\n",
      "  training loss:\t\t0.038760\n",
      "  validation loss:\t\t0.036235\n",
      "Epoch 190 of 600 took 71.082s\n",
      "  training loss:\t\t0.038745\n",
      "  validation loss:\t\t0.036259\n",
      "Epoch 191 of 600 took 71.085s\n",
      "  training loss:\t\t0.038737\n",
      "  validation loss:\t\t0.036248\n",
      "Epoch 192 of 600 took 71.050s\n",
      "  training loss:\t\t0.038741\n",
      "  validation loss:\t\t0.036232\n",
      "Epoch 193 of 600 took 71.083s\n",
      "  training loss:\t\t0.038731\n",
      "  validation loss:\t\t0.036274\n",
      "Epoch 194 of 600 took 71.034s\n",
      "  training loss:\t\t0.038719\n",
      "  validation loss:\t\t0.036383\n",
      "Epoch 195 of 600 took 71.069s\n",
      "  training loss:\t\t0.038702\n",
      "  validation loss:\t\t0.036221\n",
      "Epoch 196 of 600 took 71.043s\n",
      "  training loss:\t\t0.038718\n",
      "  validation loss:\t\t0.036238\n",
      "Epoch 197 of 600 took 71.016s\n",
      "  training loss:\t\t0.038700\n",
      "  validation loss:\t\t0.036227\n",
      "Epoch 198 of 600 took 71.105s\n",
      "  training loss:\t\t0.038711\n",
      "  validation loss:\t\t0.036302\n",
      "Epoch 199 of 600 took 71.012s\n",
      "  training loss:\t\t0.038716\n",
      "  validation loss:\t\t0.036098\n",
      "Epoch 200 of 600 took 71.016s\n",
      "  training loss:\t\t0.038700\n",
      "  validation loss:\t\t0.036328\n",
      "Epoch 201 of 600 took 71.022s\n",
      "  training loss:\t\t0.038708\n",
      "  validation loss:\t\t0.036277\n",
      "Epoch 202 of 600 took 71.001s\n",
      "  training loss:\t\t0.038687\n",
      "  validation loss:\t\t0.036269\n",
      "Epoch 203 of 600 took 71.032s\n",
      "  training loss:\t\t0.038710\n",
      "  validation loss:\t\t0.036197\n",
      "Epoch 204 of 600 took 71.001s\n",
      "  training loss:\t\t0.038701\n",
      "  validation loss:\t\t0.036290\n",
      "Epoch 205 of 600 took 71.031s\n",
      "  training loss:\t\t0.038693\n",
      "  validation loss:\t\t0.036421\n",
      "Epoch 206 of 600 took 71.046s\n",
      "  training loss:\t\t0.038674\n",
      "  validation loss:\t\t0.036303\n",
      "Epoch 207 of 600 took 70.976s\n",
      "  training loss:\t\t0.038688\n",
      "  validation loss:\t\t0.036046\n",
      "Epoch 208 of 600 took 71.025s\n",
      "  training loss:\t\t0.038679\n",
      "  validation loss:\t\t0.036370\n",
      "Epoch 209 of 600 took 71.002s\n",
      "  training loss:\t\t0.038660\n",
      "  validation loss:\t\t0.036294\n",
      "Epoch 210 of 600 took 71.031s\n",
      "  training loss:\t\t0.038666\n",
      "  validation loss:\t\t0.036118\n",
      "Epoch 211 of 600 took 70.999s\n",
      "  training loss:\t\t0.038663\n",
      "  validation loss:\t\t0.036286\n",
      "Epoch 212 of 600 took 71.007s\n",
      "  training loss:\t\t0.038652\n",
      "  validation loss:\t\t0.036103\n",
      "Epoch 213 of 600 took 71.057s\n",
      "  training loss:\t\t0.038642\n",
      "  validation loss:\t\t0.036329\n",
      "Epoch 214 of 600 took 70.998s\n",
      "  training loss:\t\t0.038692\n",
      "  validation loss:\t\t0.036184\n",
      "Epoch 215 of 600 took 71.140s\n",
      "  training loss:\t\t0.038656\n",
      "  validation loss:\t\t0.036344\n",
      "Epoch 216 of 600 took 71.038s\n",
      "  training loss:\t\t0.038671\n",
      "  validation loss:\t\t0.036085\n",
      "Epoch 217 of 600 took 70.986s\n",
      "  training loss:\t\t0.038664\n",
      "  validation loss:\t\t0.036092\n",
      "Epoch 218 of 600 took 71.006s\n",
      "  training loss:\t\t0.038649\n",
      "  validation loss:\t\t0.036329\n",
      "Epoch 219 of 600 took 71.003s\n",
      "  training loss:\t\t0.038659\n",
      "  validation loss:\t\t0.036325\n",
      "Epoch 220 of 600 took 71.029s\n",
      "  training loss:\t\t0.038647\n",
      "  validation loss:\t\t0.036205\n",
      "Epoch 221 of 600 took 71.012s\n",
      "  training loss:\t\t0.038646\n",
      "  validation loss:\t\t0.036131\n",
      "Epoch 222 of 600 took 71.047s\n",
      "  training loss:\t\t0.038654\n",
      "  validation loss:\t\t0.036143\n",
      "Epoch 223 of 600 took 71.066s\n",
      "  training loss:\t\t0.038617\n",
      "  validation loss:\t\t0.036206\n",
      "Epoch 224 of 600 took 70.999s\n",
      "  training loss:\t\t0.038623\n",
      "  validation loss:\t\t0.036130\n",
      "Epoch 225 of 600 took 71.011s\n",
      "  training loss:\t\t0.038637\n",
      "  validation loss:\t\t0.036207\n",
      "Epoch 226 of 600 took 70.981s\n",
      "  training loss:\t\t0.038620\n",
      "  validation loss:\t\t0.036082\n",
      "Epoch 227 of 600 took 71.069s\n",
      "  training loss:\t\t0.038631\n",
      "  validation loss:\t\t0.036227\n",
      "Epoch 228 of 600 took 71.032s\n",
      "  training loss:\t\t0.038632\n",
      "  validation loss:\t\t0.036152\n",
      "Epoch 229 of 600 took 71.001s\n",
      "  training loss:\t\t0.038594\n",
      "  validation loss:\t\t0.036091\n",
      "Epoch 230 of 600 took 71.018s\n",
      "  training loss:\t\t0.038629\n",
      "  validation loss:\t\t0.035986\n",
      "Epoch 231 of 600 took 70.992s\n",
      "  training loss:\t\t0.038607\n",
      "  validation loss:\t\t0.036009\n",
      "Epoch 232 of 600 took 71.031s\n",
      "  training loss:\t\t0.038610\n",
      "  validation loss:\t\t0.036135\n",
      "Epoch 233 of 600 took 71.001s\n",
      "  training loss:\t\t0.038590\n",
      "  validation loss:\t\t0.036047\n",
      "Epoch 234 of 600 took 70.995s\n",
      "  training loss:\t\t0.038592\n",
      "  validation loss:\t\t0.036124\n",
      "Epoch 235 of 600 took 71.017s\n",
      "  training loss:\t\t0.038596\n",
      "  validation loss:\t\t0.036101\n",
      "Epoch 236 of 600 took 71.010s\n",
      "  training loss:\t\t0.038614\n",
      "  validation loss:\t\t0.036410\n",
      "Epoch 237 of 600 took 71.007s\n",
      "  training loss:\t\t0.038580\n",
      "  validation loss:\t\t0.036195\n",
      "Epoch 238 of 600 took 70.990s\n",
      "  training loss:\t\t0.038584\n",
      "  validation loss:\t\t0.036106\n",
      "Epoch 239 of 600 took 70.980s\n",
      "  training loss:\t\t0.038591\n",
      "  validation loss:\t\t0.036015\n",
      "Epoch 240 of 600 took 70.993s\n",
      "  training loss:\t\t0.038578\n",
      "  validation loss:\t\t0.036002\n",
      "Epoch 241 of 600 took 70.978s\n",
      "  training loss:\t\t0.038581\n",
      "  validation loss:\t\t0.036344\n",
      "Epoch 242 of 600 took 70.990s\n",
      "  training loss:\t\t0.038573\n",
      "  validation loss:\t\t0.036078\n",
      "Epoch 243 of 600 took 70.981s\n",
      "  training loss:\t\t0.038549\n",
      "  validation loss:\t\t0.036235\n",
      "Epoch 244 of 600 took 71.031s\n",
      "  training loss:\t\t0.038561\n",
      "  validation loss:\t\t0.036340\n",
      "Epoch 245 of 600 took 71.010s\n",
      "  training loss:\t\t0.038571\n",
      "  validation loss:\t\t0.036168\n",
      "Epoch 246 of 600 took 71.026s\n",
      "  training loss:\t\t0.038552\n",
      "  validation loss:\t\t0.036102\n",
      "Epoch 247 of 600 took 71.010s\n",
      "  training loss:\t\t0.038533\n",
      "  validation loss:\t\t0.036151\n",
      "Epoch 248 of 600 took 71.028s\n",
      "  training loss:\t\t0.038555\n",
      "  validation loss:\t\t0.036066\n",
      "Epoch 249 of 600 took 70.998s\n",
      "  training loss:\t\t0.038582\n",
      "  validation loss:\t\t0.036116\n",
      "Epoch 250 of 600 took 70.993s\n",
      "  training loss:\t\t0.038564\n",
      "  validation loss:\t\t0.036197\n",
      "Epoch 251 of 600 took 70.994s\n",
      "  training loss:\t\t0.038567\n",
      "  validation loss:\t\t0.036054\n",
      "Epoch 252 of 600 took 71.027s\n",
      "  training loss:\t\t0.038554\n",
      "  validation loss:\t\t0.036238\n",
      "Epoch 253 of 600 took 71.065s\n",
      "  training loss:\t\t0.038559\n",
      "  validation loss:\t\t0.036246\n",
      "Epoch 254 of 600 took 70.970s\n",
      "  training loss:\t\t0.038558\n",
      "  validation loss:\t\t0.036187\n",
      "Epoch 255 of 600 took 70.978s\n",
      "  training loss:\t\t0.038541\n",
      "  validation loss:\t\t0.036193\n",
      "Epoch 256 of 600 took 70.956s\n",
      "  training loss:\t\t0.038506\n",
      "  validation loss:\t\t0.036270\n",
      "Epoch 257 of 600 took 71.036s\n",
      "  training loss:\t\t0.038539\n",
      "  validation loss:\t\t0.036308\n",
      "Epoch 258 of 600 took 70.992s\n",
      "  training loss:\t\t0.038545\n",
      "  validation loss:\t\t0.036057\n",
      "Epoch 259 of 600 took 71.008s\n",
      "  training loss:\t\t0.038524\n",
      "  validation loss:\t\t0.036057\n",
      "Epoch 260 of 600 took 71.011s\n",
      "  training loss:\t\t0.038523\n",
      "  validation loss:\t\t0.036248\n",
      "Epoch 261 of 600 took 70.987s\n",
      "  training loss:\t\t0.038521\n",
      "  validation loss:\t\t0.036310\n",
      "Epoch 262 of 600 took 71.015s\n",
      "  training loss:\t\t0.038498\n",
      "  validation loss:\t\t0.036199\n",
      "Epoch 263 of 600 took 70.996s\n",
      "  training loss:\t\t0.038503\n",
      "  validation loss:\t\t0.035911\n",
      "Epoch 264 of 600 took 70.990s\n",
      "  training loss:\t\t0.038530\n",
      "  validation loss:\t\t0.036060\n",
      "Epoch 265 of 600 took 71.061s\n",
      "  training loss:\t\t0.038502\n",
      "  validation loss:\t\t0.036236\n",
      "Epoch 266 of 600 took 70.992s\n",
      "  training loss:\t\t0.038506\n",
      "  validation loss:\t\t0.036006\n",
      "Epoch 267 of 600 took 71.015s\n",
      "  training loss:\t\t0.038499\n",
      "  validation loss:\t\t0.036046\n",
      "Epoch 268 of 600 took 71.010s\n",
      "  training loss:\t\t0.038498\n",
      "  validation loss:\t\t0.036059\n",
      "Epoch 269 of 600 took 71.045s\n",
      "  training loss:\t\t0.038494\n",
      "  validation loss:\t\t0.036176\n",
      "Epoch 270 of 600 took 71.058s\n",
      "  training loss:\t\t0.038483\n",
      "  validation loss:\t\t0.036128\n",
      "Epoch 271 of 600 took 71.019s\n",
      "  training loss:\t\t0.038485\n",
      "  validation loss:\t\t0.036128\n",
      "Epoch 272 of 600 took 71.015s\n",
      "  training loss:\t\t0.038485\n",
      "  validation loss:\t\t0.036101\n",
      "Epoch 273 of 600 took 71.075s\n",
      "  training loss:\t\t0.038466\n",
      "  validation loss:\t\t0.036239\n",
      "Epoch 274 of 600 took 71.104s\n",
      "  training loss:\t\t0.038501\n",
      "  validation loss:\t\t0.036400\n",
      "Epoch 275 of 600 took 71.089s\n",
      "  training loss:\t\t0.038483\n",
      "  validation loss:\t\t0.036001\n",
      "Epoch 276 of 600 took 71.075s\n",
      "  training loss:\t\t0.038460\n",
      "  validation loss:\t\t0.036310\n",
      "Epoch 277 of 600 took 71.010s\n",
      "  training loss:\t\t0.038460\n",
      "  validation loss:\t\t0.035972\n",
      "Epoch 278 of 600 took 70.998s\n",
      "  training loss:\t\t0.038475\n",
      "  validation loss:\t\t0.036000\n",
      "Epoch 279 of 600 took 71.001s\n",
      "  training loss:\t\t0.038469\n",
      "  validation loss:\t\t0.036034\n",
      "Epoch 280 of 600 took 71.013s\n",
      "  training loss:\t\t0.038456\n",
      "  validation loss:\t\t0.036073\n",
      "Epoch 281 of 600 took 71.022s\n",
      "  training loss:\t\t0.038444\n",
      "  validation loss:\t\t0.036102\n",
      "Epoch 282 of 600 took 71.161s\n",
      "  training loss:\t\t0.038431\n",
      "  validation loss:\t\t0.036024\n",
      "Epoch 283 of 600 took 71.009s\n",
      "  training loss:\t\t0.038473\n",
      "  validation loss:\t\t0.035956\n",
      "Epoch 284 of 600 took 71.035s\n",
      "  training loss:\t\t0.038465\n",
      "  validation loss:\t\t0.036054\n",
      "Epoch 285 of 600 took 70.999s\n",
      "  training loss:\t\t0.038448\n",
      "  validation loss:\t\t0.036176\n",
      "Epoch 286 of 600 took 71.087s\n",
      "  training loss:\t\t0.038463\n",
      "  validation loss:\t\t0.036164\n",
      "Epoch 287 of 600 took 71.032s\n",
      "  training loss:\t\t0.038433\n",
      "  validation loss:\t\t0.036028\n",
      "Epoch 288 of 600 took 70.951s\n",
      "  training loss:\t\t0.038444\n",
      "  validation loss:\t\t0.035987\n",
      "Epoch 289 of 600 took 71.030s\n",
      "  training loss:\t\t0.038416\n",
      "  validation loss:\t\t0.036039\n",
      "Epoch 290 of 600 took 70.979s\n",
      "  training loss:\t\t0.038424\n",
      "  validation loss:\t\t0.036090\n",
      "Epoch 291 of 600 took 71.035s\n",
      "  training loss:\t\t0.038402\n",
      "  validation loss:\t\t0.036077\n",
      "Epoch 292 of 600 took 71.012s\n",
      "  training loss:\t\t0.038420\n",
      "  validation loss:\t\t0.036256\n",
      "Epoch 293 of 600 took 70.995s\n",
      "  training loss:\t\t0.038446\n",
      "  validation loss:\t\t0.036005\n",
      "Epoch 294 of 600 took 71.000s\n",
      "  training loss:\t\t0.038391\n",
      "  validation loss:\t\t0.036087\n",
      "Epoch 295 of 600 took 71.013s\n",
      "  training loss:\t\t0.038424\n",
      "  validation loss:\t\t0.036060\n",
      "Epoch 296 of 600 took 71.015s\n",
      "  training loss:\t\t0.038416\n",
      "  validation loss:\t\t0.036116\n",
      "Epoch 297 of 600 took 71.012s\n",
      "  training loss:\t\t0.038399\n",
      "  validation loss:\t\t0.035975\n",
      "Epoch 298 of 600 took 71.002s\n",
      "  training loss:\t\t0.038415\n",
      "  validation loss:\t\t0.036158\n",
      "Epoch 299 of 600 took 71.067s\n",
      "  training loss:\t\t0.038415\n",
      "  validation loss:\t\t0.036135\n",
      "Epoch 300 of 600 took 71.015s\n",
      "  training loss:\t\t0.038381\n",
      "  validation loss:\t\t0.036099\n",
      "Epoch 301 of 600 took 71.012s\n",
      "  training loss:\t\t0.038383\n",
      "  validation loss:\t\t0.036283\n",
      "Epoch 302 of 600 took 71.018s\n",
      "  training loss:\t\t0.038407\n",
      "  validation loss:\t\t0.036019\n",
      "Epoch 303 of 600 took 71.083s\n",
      "  training loss:\t\t0.038377\n",
      "  validation loss:\t\t0.036047\n",
      "Epoch 304 of 600 took 71.049s\n",
      "  training loss:\t\t0.038401\n",
      "  validation loss:\t\t0.036027\n",
      "Epoch 305 of 600 took 70.998s\n",
      "  training loss:\t\t0.038374\n",
      "  validation loss:\t\t0.036202\n",
      "Epoch 306 of 600 took 71.016s\n",
      "  training loss:\t\t0.038385\n",
      "  validation loss:\t\t0.036001\n",
      "Epoch 307 of 600 took 70.995s\n",
      "  training loss:\t\t0.038409\n",
      "  validation loss:\t\t0.035999\n",
      "Epoch 308 of 600 took 71.013s\n",
      "  training loss:\t\t0.038375\n",
      "  validation loss:\t\t0.035966\n",
      "Epoch 309 of 600 took 71.005s\n",
      "  training loss:\t\t0.038391\n",
      "  validation loss:\t\t0.035866\n",
      "Epoch 310 of 600 took 70.987s\n",
      "  training loss:\t\t0.038374\n",
      "  validation loss:\t\t0.035999\n",
      "Epoch 311 of 600 took 70.994s\n",
      "  training loss:\t\t0.038360\n",
      "  validation loss:\t\t0.036005\n",
      "Epoch 312 of 600 took 70.994s\n",
      "  training loss:\t\t0.038343\n",
      "  validation loss:\t\t0.036006\n",
      "Epoch 313 of 600 took 70.944s\n",
      "  training loss:\t\t0.038391\n",
      "  validation loss:\t\t0.036079\n",
      "Epoch 314 of 600 took 71.009s\n",
      "  training loss:\t\t0.038367\n",
      "  validation loss:\t\t0.036047\n",
      "Epoch 315 of 600 took 71.006s\n",
      "  training loss:\t\t0.038333\n",
      "  validation loss:\t\t0.035979\n",
      "Epoch 316 of 600 took 71.087s\n",
      "  training loss:\t\t0.038363\n",
      "  validation loss:\t\t0.036269\n",
      "Epoch 317 of 600 took 70.994s\n",
      "  training loss:\t\t0.038365\n",
      "  validation loss:\t\t0.036142\n",
      "Epoch 318 of 600 took 70.986s\n",
      "  training loss:\t\t0.038344\n",
      "  validation loss:\t\t0.036237\n",
      "Epoch 319 of 600 took 70.985s\n",
      "  training loss:\t\t0.038344\n",
      "  validation loss:\t\t0.036091\n",
      "Epoch 320 of 600 took 71.019s\n",
      "  training loss:\t\t0.038322\n",
      "  validation loss:\t\t0.035990\n",
      "Epoch 321 of 600 took 71.021s\n",
      "  training loss:\t\t0.038329\n",
      "  validation loss:\t\t0.036055\n",
      "Epoch 322 of 600 took 71.000s\n",
      "  training loss:\t\t0.038322\n",
      "  validation loss:\t\t0.036294\n",
      "Epoch 323 of 600 took 71.096s\n",
      "  training loss:\t\t0.038335\n",
      "  validation loss:\t\t0.036114\n",
      "Epoch 324 of 600 took 71.015s\n",
      "  training loss:\t\t0.038324\n",
      "  validation loss:\t\t0.036254\n",
      "Epoch 325 of 600 took 71.003s\n",
      "  training loss:\t\t0.038306\n",
      "  validation loss:\t\t0.036005\n",
      "Epoch 326 of 600 took 71.001s\n",
      "  training loss:\t\t0.038331\n",
      "  validation loss:\t\t0.036035\n",
      "Epoch 327 of 600 took 70.977s\n",
      "  training loss:\t\t0.038308\n",
      "  validation loss:\t\t0.036087\n",
      "Epoch 328 of 600 took 71.009s\n",
      "  training loss:\t\t0.038322\n",
      "  validation loss:\t\t0.036057\n",
      "Epoch 329 of 600 took 71.029s\n",
      "  training loss:\t\t0.038303\n",
      "  validation loss:\t\t0.035996\n",
      "Epoch 330 of 600 took 71.022s\n",
      "  training loss:\t\t0.038331\n",
      "  validation loss:\t\t0.036036\n",
      "Epoch 331 of 600 took 71.008s\n",
      "  training loss:\t\t0.038300\n",
      "  validation loss:\t\t0.035908\n",
      "Epoch 332 of 600 took 71.007s\n",
      "  training loss:\t\t0.038332\n",
      "  validation loss:\t\t0.036100\n",
      "Epoch 333 of 600 took 70.993s\n",
      "  training loss:\t\t0.038330\n",
      "  validation loss:\t\t0.036113\n",
      "Epoch 334 of 600 took 70.997s\n",
      "  training loss:\t\t0.038322\n",
      "  validation loss:\t\t0.036008\n",
      "Epoch 335 of 600 took 70.990s\n",
      "  training loss:\t\t0.038316\n",
      "  validation loss:\t\t0.036131\n",
      "Epoch 336 of 600 took 70.963s\n",
      "  training loss:\t\t0.038311\n",
      "  validation loss:\t\t0.035977\n",
      "Epoch 337 of 600 took 70.970s\n",
      "  training loss:\t\t0.038278\n",
      "  validation loss:\t\t0.035996\n",
      "Epoch 338 of 600 took 71.021s\n",
      "  training loss:\t\t0.038296\n",
      "  validation loss:\t\t0.036144\n",
      "Epoch 339 of 600 took 71.009s\n",
      "  training loss:\t\t0.038277\n",
      "  validation loss:\t\t0.036005\n",
      "Epoch 340 of 600 took 71.040s\n",
      "  training loss:\t\t0.038295\n",
      "  validation loss:\t\t0.035967\n",
      "Epoch 341 of 600 took 71.034s\n",
      "  training loss:\t\t0.038274\n",
      "  validation loss:\t\t0.036144\n",
      "Epoch 342 of 600 took 71.072s\n",
      "  training loss:\t\t0.038296\n",
      "  validation loss:\t\t0.036098\n",
      "Epoch 343 of 600 took 71.044s\n",
      "  training loss:\t\t0.038277\n",
      "  validation loss:\t\t0.035924\n",
      "Epoch 344 of 600 took 71.091s\n",
      "  training loss:\t\t0.038253\n",
      "  validation loss:\t\t0.036026\n",
      "Epoch 345 of 600 took 70.995s\n",
      "  training loss:\t\t0.038258\n",
      "  validation loss:\t\t0.035933\n",
      "Epoch 346 of 600 took 71.057s\n",
      "  training loss:\t\t0.038274\n",
      "  validation loss:\t\t0.035980\n",
      "Epoch 347 of 600 took 71.002s\n",
      "  training loss:\t\t0.038262\n",
      "  validation loss:\t\t0.036026\n",
      "Epoch 348 of 600 took 71.040s\n",
      "  training loss:\t\t0.038260\n",
      "  validation loss:\t\t0.035931\n",
      "Epoch 349 of 600 took 70.982s\n",
      "  training loss:\t\t0.038264\n",
      "  validation loss:\t\t0.035885\n",
      "Epoch 350 of 600 took 71.035s\n",
      "  training loss:\t\t0.038230\n",
      "  validation loss:\t\t0.036178\n",
      "Epoch 351 of 600 took 71.022s\n",
      "  training loss:\t\t0.038250\n",
      "  validation loss:\t\t0.036089\n",
      "Epoch 352 of 600 took 70.990s\n",
      "  training loss:\t\t0.038246\n",
      "  validation loss:\t\t0.035975\n",
      "Epoch 353 of 600 took 70.973s\n",
      "  training loss:\t\t0.038241\n",
      "  validation loss:\t\t0.035968\n",
      "Epoch 354 of 600 took 70.953s\n",
      "  training loss:\t\t0.038216\n",
      "  validation loss:\t\t0.036061\n",
      "Epoch 355 of 600 took 70.951s\n",
      "  training loss:\t\t0.038260\n",
      "  validation loss:\t\t0.036097\n",
      "Epoch 356 of 600 took 70.949s\n",
      "  training loss:\t\t0.038239\n",
      "  validation loss:\t\t0.035975\n",
      "Epoch 357 of 600 took 70.996s\n",
      "  training loss:\t\t0.038221\n",
      "  validation loss:\t\t0.035903\n",
      "Epoch 358 of 600 took 71.026s\n",
      "  training loss:\t\t0.038222\n",
      "  validation loss:\t\t0.036198\n",
      "Epoch 359 of 600 took 71.008s\n",
      "  training loss:\t\t0.038231\n",
      "  validation loss:\t\t0.036170\n",
      "Epoch 360 of 600 took 70.999s\n",
      "  training loss:\t\t0.038229\n",
      "  validation loss:\t\t0.035966\n",
      "Epoch 361 of 600 took 70.987s\n",
      "  training loss:\t\t0.038180\n",
      "  validation loss:\t\t0.036119\n",
      "Epoch 362 of 600 took 71.021s\n",
      "  training loss:\t\t0.038244\n",
      "  validation loss:\t\t0.036066\n",
      "Epoch 363 of 600 took 71.064s\n",
      "  training loss:\t\t0.038216\n",
      "  validation loss:\t\t0.036064\n",
      "Epoch 364 of 600 took 70.984s\n",
      "  training loss:\t\t0.038232\n",
      "  validation loss:\t\t0.035928\n",
      "Epoch 365 of 600 took 71.002s\n",
      "  training loss:\t\t0.038198\n",
      "  validation loss:\t\t0.035842\n",
      "Epoch 366 of 600 took 70.989s\n",
      "  training loss:\t\t0.038191\n",
      "  validation loss:\t\t0.035952\n",
      "Epoch 367 of 600 took 71.008s\n",
      "  training loss:\t\t0.038199\n",
      "  validation loss:\t\t0.035968\n",
      "Epoch 368 of 600 took 70.989s\n",
      "  training loss:\t\t0.038195\n",
      "  validation loss:\t\t0.036174\n",
      "Epoch 369 of 600 took 71.002s\n",
      "  training loss:\t\t0.038215\n",
      "  validation loss:\t\t0.035917\n",
      "Epoch 370 of 600 took 71.017s\n",
      "  training loss:\t\t0.038191\n",
      "  validation loss:\t\t0.035972\n",
      "Epoch 371 of 600 took 71.030s\n",
      "  training loss:\t\t0.038194\n",
      "  validation loss:\t\t0.035924\n",
      "Epoch 372 of 600 took 71.039s\n",
      "  training loss:\t\t0.038174\n",
      "  validation loss:\t\t0.035915\n",
      "Epoch 373 of 600 took 71.048s\n",
      "  training loss:\t\t0.038215\n",
      "  validation loss:\t\t0.036031\n",
      "Epoch 374 of 600 took 71.018s\n",
      "  training loss:\t\t0.038210\n",
      "  validation loss:\t\t0.035973\n",
      "Epoch 375 of 600 took 71.026s\n",
      "  training loss:\t\t0.038198\n",
      "  validation loss:\t\t0.036151\n",
      "Epoch 376 of 600 took 71.005s\n",
      "  training loss:\t\t0.038172\n",
      "  validation loss:\t\t0.035888\n",
      "Epoch 377 of 600 took 71.046s\n",
      "  training loss:\t\t0.038175\n",
      "  validation loss:\t\t0.036026\n",
      "Epoch 378 of 600 took 70.987s\n",
      "  training loss:\t\t0.038193\n",
      "  validation loss:\t\t0.035884\n",
      "Epoch 379 of 600 took 71.112s\n",
      "  training loss:\t\t0.038188\n",
      "  validation loss:\t\t0.036019\n",
      "Epoch 380 of 600 took 71.050s\n",
      "  training loss:\t\t0.038172\n",
      "  validation loss:\t\t0.035872\n",
      "Epoch 381 of 600 took 71.007s\n",
      "  training loss:\t\t0.038173\n",
      "  validation loss:\t\t0.035956\n",
      "Epoch 382 of 600 took 71.031s\n",
      "  training loss:\t\t0.038156\n",
      "  validation loss:\t\t0.035959\n",
      "Epoch 383 of 600 took 71.009s\n",
      "  training loss:\t\t0.038165\n",
      "  validation loss:\t\t0.035920\n",
      "Epoch 384 of 600 took 71.037s\n",
      "  training loss:\t\t0.038179\n",
      "  validation loss:\t\t0.036139\n",
      "Epoch 385 of 600 took 71.017s\n",
      "  training loss:\t\t0.038142\n",
      "  validation loss:\t\t0.035964\n",
      "Epoch 386 of 600 took 71.040s\n",
      "  training loss:\t\t0.038178\n",
      "  validation loss:\t\t0.036023\n",
      "Epoch 387 of 600 took 71.069s\n",
      "  training loss:\t\t0.038144\n",
      "  validation loss:\t\t0.035879\n",
      "Epoch 388 of 600 took 71.019s\n",
      "  training loss:\t\t0.038124\n",
      "  validation loss:\t\t0.035894\n",
      "Epoch 389 of 600 took 71.017s\n",
      "  training loss:\t\t0.038144\n",
      "  validation loss:\t\t0.036034\n",
      "Epoch 390 of 600 took 71.011s\n",
      "  training loss:\t\t0.038128\n",
      "  validation loss:\t\t0.036014\n",
      "Epoch 391 of 600 took 70.951s\n",
      "  training loss:\t\t0.038153\n",
      "  validation loss:\t\t0.036186\n",
      "Epoch 392 of 600 took 71.003s\n",
      "  training loss:\t\t0.038137\n",
      "  validation loss:\t\t0.035812\n",
      "Epoch 393 of 600 took 71.005s\n",
      "  training loss:\t\t0.038146\n",
      "  validation loss:\t\t0.035930\n",
      "Epoch 394 of 600 took 71.016s\n",
      "  training loss:\t\t0.038152\n",
      "  validation loss:\t\t0.035907\n",
      "Epoch 395 of 600 took 71.010s\n",
      "  training loss:\t\t0.038120\n",
      "  validation loss:\t\t0.035819\n",
      "Epoch 396 of 600 took 71.001s\n",
      "  training loss:\t\t0.038135\n",
      "  validation loss:\t\t0.035872\n",
      "Epoch 397 of 600 took 71.018s\n",
      "  training loss:\t\t0.038098\n",
      "  validation loss:\t\t0.035937\n",
      "Epoch 398 of 600 took 70.994s\n",
      "  training loss:\t\t0.038130\n",
      "  validation loss:\t\t0.036202\n",
      "Epoch 399 of 600 took 71.030s\n",
      "  training loss:\t\t0.038134\n",
      "  validation loss:\t\t0.035883\n",
      "Epoch 400 of 600 took 70.985s\n",
      "  training loss:\t\t0.038109\n",
      "  validation loss:\t\t0.036063\n",
      "Epoch 401 of 600 took 71.006s\n",
      "  training loss:\t\t0.038094\n",
      "  validation loss:\t\t0.036036\n",
      "Epoch 402 of 600 took 71.009s\n",
      "  training loss:\t\t0.038101\n",
      "  validation loss:\t\t0.035844\n",
      "Epoch 403 of 600 took 71.034s\n",
      "  training loss:\t\t0.038120\n",
      "  validation loss:\t\t0.035869\n",
      "Epoch 404 of 600 took 71.052s\n",
      "  training loss:\t\t0.038107\n",
      "  validation loss:\t\t0.035806\n",
      "Epoch 405 of 600 took 71.017s\n",
      "  training loss:\t\t0.038108\n",
      "  validation loss:\t\t0.035896\n",
      "Epoch 406 of 600 took 71.032s\n",
      "  training loss:\t\t0.038093\n",
      "  validation loss:\t\t0.036129\n",
      "Epoch 407 of 600 took 71.014s\n",
      "  training loss:\t\t0.038090\n",
      "  validation loss:\t\t0.035975\n",
      "Epoch 408 of 600 took 70.990s\n",
      "  training loss:\t\t0.038086\n",
      "  validation loss:\t\t0.035944\n",
      "Epoch 409 of 600 took 71.022s\n",
      "  training loss:\t\t0.038107\n",
      "  validation loss:\t\t0.035776\n",
      "Epoch 410 of 600 took 70.995s\n",
      "  training loss:\t\t0.038076\n",
      "  validation loss:\t\t0.035906\n",
      "Epoch 411 of 600 took 71.016s\n",
      "  training loss:\t\t0.038082\n",
      "  validation loss:\t\t0.035841\n",
      "Epoch 412 of 600 took 71.028s\n",
      "  training loss:\t\t0.038082\n",
      "  validation loss:\t\t0.035959\n",
      "Epoch 413 of 600 took 71.022s\n",
      "  training loss:\t\t0.038065\n",
      "  validation loss:\t\t0.035759\n",
      "Epoch 414 of 600 took 71.022s\n",
      "  training loss:\t\t0.038069\n",
      "  validation loss:\t\t0.036010\n",
      "Epoch 415 of 600 took 70.990s\n",
      "  training loss:\t\t0.038053\n",
      "  validation loss:\t\t0.035913\n",
      "Epoch 416 of 600 took 71.004s\n",
      "  training loss:\t\t0.038095\n",
      "  validation loss:\t\t0.036174\n",
      "Epoch 417 of 600 took 70.997s\n",
      "  training loss:\t\t0.038081\n",
      "  validation loss:\t\t0.035865\n",
      "Epoch 418 of 600 took 71.024s\n",
      "  training loss:\t\t0.038076\n",
      "  validation loss:\t\t0.035943\n",
      "Epoch 419 of 600 took 71.019s\n",
      "  training loss:\t\t0.038047\n",
      "  validation loss:\t\t0.036088\n",
      "Epoch 420 of 600 took 71.009s\n",
      "  training loss:\t\t0.038083\n",
      "  validation loss:\t\t0.036135\n",
      "Epoch 421 of 600 took 71.017s\n",
      "  training loss:\t\t0.038044\n",
      "  validation loss:\t\t0.035876\n",
      "Epoch 422 of 600 took 70.999s\n",
      "  training loss:\t\t0.038043\n",
      "  validation loss:\t\t0.035867\n",
      "Epoch 423 of 600 took 71.028s\n",
      "  training loss:\t\t0.038055\n",
      "  validation loss:\t\t0.035986\n",
      "Epoch 424 of 600 took 71.000s\n",
      "  training loss:\t\t0.038060\n",
      "  validation loss:\t\t0.036020\n",
      "Epoch 425 of 600 took 71.003s\n",
      "  training loss:\t\t0.038072\n",
      "  validation loss:\t\t0.035853\n",
      "Epoch 426 of 600 took 71.020s\n",
      "  training loss:\t\t0.038039\n",
      "  validation loss:\t\t0.036002\n",
      "Epoch 427 of 600 took 71.018s\n",
      "  training loss:\t\t0.038061\n",
      "  validation loss:\t\t0.035879\n",
      "Epoch 428 of 600 took 71.111s\n",
      "  training loss:\t\t0.038043\n",
      "  validation loss:\t\t0.035836\n",
      "Epoch 429 of 600 took 71.046s\n",
      "  training loss:\t\t0.038051\n",
      "  validation loss:\t\t0.035779\n",
      "Epoch 430 of 600 took 71.046s\n",
      "  training loss:\t\t0.038027\n",
      "  validation loss:\t\t0.035892\n",
      "Epoch 431 of 600 took 71.072s\n",
      "  training loss:\t\t0.038030\n",
      "  validation loss:\t\t0.035846\n",
      "Epoch 432 of 600 took 70.997s\n",
      "  training loss:\t\t0.038040\n",
      "  validation loss:\t\t0.036033\n",
      "Epoch 433 of 600 took 71.002s\n",
      "  training loss:\t\t0.038027\n",
      "  validation loss:\t\t0.035891\n",
      "Epoch 434 of 600 took 71.040s\n",
      "  training loss:\t\t0.038009\n",
      "  validation loss:\t\t0.036123\n",
      "Epoch 435 of 600 took 70.937s\n",
      "  training loss:\t\t0.038024\n",
      "  validation loss:\t\t0.036020\n",
      "Epoch 436 of 600 took 71.003s\n",
      "  training loss:\t\t0.038002\n",
      "  validation loss:\t\t0.035975\n",
      "Epoch 437 of 600 took 71.006s\n",
      "  training loss:\t\t0.038007\n",
      "  validation loss:\t\t0.036126\n",
      "Epoch 438 of 600 took 71.015s\n",
      "  training loss:\t\t0.037985\n",
      "  validation loss:\t\t0.035796\n",
      "Epoch 439 of 600 took 71.036s\n",
      "  training loss:\t\t0.038028\n",
      "  validation loss:\t\t0.035899\n",
      "Epoch 440 of 600 took 71.015s\n",
      "  training loss:\t\t0.037997\n",
      "  validation loss:\t\t0.035906\n",
      "Epoch 441 of 600 took 71.008s\n",
      "  training loss:\t\t0.037998\n",
      "  validation loss:\t\t0.035778\n",
      "Epoch 442 of 600 took 71.013s\n",
      "  training loss:\t\t0.037982\n",
      "  validation loss:\t\t0.035893\n",
      "Epoch 443 of 600 took 71.032s\n",
      "  training loss:\t\t0.038022\n",
      "  validation loss:\t\t0.036153\n",
      "Epoch 444 of 600 took 71.008s\n",
      "  training loss:\t\t0.038009\n",
      "  validation loss:\t\t0.035941\n",
      "Epoch 445 of 600 took 71.032s\n",
      "  training loss:\t\t0.037999\n",
      "  validation loss:\t\t0.036036\n",
      "Epoch 446 of 600 took 71.041s\n",
      "  training loss:\t\t0.037968\n",
      "  validation loss:\t\t0.035744\n",
      "Epoch 447 of 600 took 71.016s\n",
      "  training loss:\t\t0.037984\n",
      "  validation loss:\t\t0.036138\n",
      "Epoch 448 of 600 took 70.996s\n",
      "  training loss:\t\t0.038005\n",
      "  validation loss:\t\t0.035984\n",
      "Epoch 449 of 600 took 70.981s\n",
      "  training loss:\t\t0.037954\n",
      "  validation loss:\t\t0.035829\n",
      "Epoch 450 of 600 took 71.031s\n",
      "  training loss:\t\t0.037978\n",
      "  validation loss:\t\t0.035897\n",
      "Epoch 451 of 600 took 71.037s\n",
      "  training loss:\t\t0.037993\n",
      "  validation loss:\t\t0.035865\n",
      "Epoch 452 of 600 took 70.998s\n",
      "  training loss:\t\t0.037967\n",
      "  validation loss:\t\t0.036098\n",
      "Epoch 453 of 600 took 71.022s\n",
      "  training loss:\t\t0.037955\n",
      "  validation loss:\t\t0.035955\n",
      "Epoch 454 of 600 took 71.001s\n",
      "  training loss:\t\t0.037994\n",
      "  validation loss:\t\t0.035969\n",
      "Epoch 455 of 600 took 71.043s\n",
      "  training loss:\t\t0.037972\n",
      "  validation loss:\t\t0.035848\n",
      "Epoch 456 of 600 took 71.009s\n",
      "  training loss:\t\t0.037956\n",
      "  validation loss:\t\t0.035850\n",
      "Epoch 457 of 600 took 70.976s\n",
      "  training loss:\t\t0.037949\n",
      "  validation loss:\t\t0.035825\n",
      "Epoch 458 of 600 took 71.029s\n",
      "  training loss:\t\t0.037963\n",
      "  validation loss:\t\t0.035792\n",
      "Epoch 459 of 600 took 70.996s\n",
      "  training loss:\t\t0.037977\n",
      "  validation loss:\t\t0.035888\n",
      "Epoch 460 of 600 took 71.014s\n",
      "  training loss:\t\t0.037955\n",
      "  validation loss:\t\t0.036106\n",
      "Epoch 461 of 600 took 71.021s\n",
      "  training loss:\t\t0.037939\n",
      "  validation loss:\t\t0.035986\n",
      "Epoch 462 of 600 took 70.956s\n",
      "  training loss:\t\t0.037932\n",
      "  validation loss:\t\t0.035974\n",
      "Epoch 463 of 600 took 71.010s\n",
      "  training loss:\t\t0.037930\n",
      "  validation loss:\t\t0.035835\n",
      "Epoch 464 of 600 took 71.032s\n",
      "  training loss:\t\t0.037925\n",
      "  validation loss:\t\t0.035941\n",
      "Epoch 465 of 600 took 70.997s\n",
      "  training loss:\t\t0.037950\n",
      "  validation loss:\t\t0.036247\n",
      "Epoch 466 of 600 took 71.004s\n",
      "  training loss:\t\t0.037945\n",
      "  validation loss:\t\t0.035956\n",
      "Epoch 467 of 600 took 71.080s\n",
      "  training loss:\t\t0.037929\n",
      "  validation loss:\t\t0.035846\n",
      "Epoch 468 of 600 took 71.055s\n",
      "  training loss:\t\t0.037932\n",
      "  validation loss:\t\t0.035812\n",
      "Epoch 469 of 600 took 71.065s\n",
      "  training loss:\t\t0.037907\n",
      "  validation loss:\t\t0.035948\n",
      "Epoch 470 of 600 took 71.057s\n",
      "  training loss:\t\t0.037925\n",
      "  validation loss:\t\t0.036062\n",
      "Epoch 471 of 600 took 70.976s\n",
      "  training loss:\t\t0.037921\n",
      "  validation loss:\t\t0.035895\n",
      "Epoch 472 of 600 took 71.033s\n",
      "  training loss:\t\t0.037909\n",
      "  validation loss:\t\t0.036161\n",
      "Epoch 473 of 600 took 71.022s\n",
      "  training loss:\t\t0.037906\n",
      "  validation loss:\t\t0.035849\n",
      "Epoch 474 of 600 took 71.006s\n",
      "  training loss:\t\t0.037904\n",
      "  validation loss:\t\t0.036080\n",
      "Epoch 475 of 600 took 71.056s\n",
      "  training loss:\t\t0.037913\n",
      "  validation loss:\t\t0.035866\n",
      "Epoch 476 of 600 took 71.057s\n",
      "  training loss:\t\t0.037895\n",
      "  validation loss:\t\t0.035873\n",
      "Epoch 477 of 600 took 71.023s\n",
      "  training loss:\t\t0.037880\n",
      "  validation loss:\t\t0.035883\n",
      "Epoch 478 of 600 took 71.041s\n",
      "  training loss:\t\t0.037925\n",
      "  validation loss:\t\t0.036156\n",
      "Epoch 479 of 600 took 71.019s\n",
      "  training loss:\t\t0.037905\n",
      "  validation loss:\t\t0.035799\n",
      "Epoch 480 of 600 took 71.096s\n",
      "  training loss:\t\t0.037927\n",
      "  validation loss:\t\t0.035863\n",
      "Epoch 481 of 600 took 71.191s\n",
      "  training loss:\t\t0.037903\n",
      "  validation loss:\t\t0.035743\n",
      "Epoch 482 of 600 took 71.207s\n",
      "  training loss:\t\t0.037894\n",
      "  validation loss:\t\t0.035733\n",
      "Epoch 483 of 600 took 71.104s\n",
      "  training loss:\t\t0.037886\n",
      "  validation loss:\t\t0.035846\n",
      "Epoch 484 of 600 took 71.006s\n",
      "  training loss:\t\t0.037882\n",
      "  validation loss:\t\t0.035971\n",
      "Epoch 485 of 600 took 71.019s\n",
      "  training loss:\t\t0.037887\n",
      "  validation loss:\t\t0.035803\n",
      "Epoch 486 of 600 took 70.991s\n",
      "  training loss:\t\t0.037880\n",
      "  validation loss:\t\t0.036062\n",
      "Epoch 487 of 600 took 70.993s\n",
      "  training loss:\t\t0.037879\n",
      "  validation loss:\t\t0.035753\n",
      "Epoch 488 of 600 took 70.983s\n",
      "  training loss:\t\t0.037888\n",
      "  validation loss:\t\t0.035893\n",
      "Epoch 489 of 600 took 71.005s\n",
      "  training loss:\t\t0.037868\n",
      "  validation loss:\t\t0.036025\n",
      "Epoch 490 of 600 took 71.055s\n",
      "  training loss:\t\t0.037861\n",
      "  validation loss:\t\t0.035851\n",
      "Epoch 491 of 600 took 71.045s\n",
      "  training loss:\t\t0.037881\n",
      "  validation loss:\t\t0.035892\n",
      "Epoch 492 of 600 took 71.021s\n",
      "  training loss:\t\t0.037836\n",
      "  validation loss:\t\t0.035779\n",
      "Epoch 493 of 600 took 71.000s\n",
      "  training loss:\t\t0.037849\n",
      "  validation loss:\t\t0.035934\n",
      "Epoch 494 of 600 took 71.010s\n",
      "  training loss:\t\t0.037832\n",
      "  validation loss:\t\t0.035856\n",
      "Epoch 495 of 600 took 70.997s\n",
      "  training loss:\t\t0.037865\n",
      "  validation loss:\t\t0.035844\n",
      "Epoch 496 of 600 took 70.976s\n",
      "  training loss:\t\t0.037843\n",
      "  validation loss:\t\t0.035862\n",
      "Epoch 497 of 600 took 71.002s\n",
      "  training loss:\t\t0.037848\n",
      "  validation loss:\t\t0.035870\n",
      "Epoch 498 of 600 took 71.046s\n",
      "  training loss:\t\t0.037855\n",
      "  validation loss:\t\t0.035741\n",
      "Epoch 499 of 600 took 71.016s\n",
      "  training loss:\t\t0.037852\n",
      "  validation loss:\t\t0.035988\n",
      "Epoch 500 of 600 took 71.014s\n",
      "  training loss:\t\t0.037854\n",
      "  validation loss:\t\t0.035809\n",
      "Epoch 501 of 600 took 70.993s\n",
      "  training loss:\t\t0.037843\n",
      "  validation loss:\t\t0.035855\n",
      "Epoch 502 of 600 took 71.016s\n",
      "  training loss:\t\t0.037833\n",
      "  validation loss:\t\t0.035855\n",
      "Epoch 503 of 600 took 71.005s\n",
      "  training loss:\t\t0.037829\n",
      "  validation loss:\t\t0.035809\n",
      "Epoch 504 of 600 took 70.982s\n",
      "  training loss:\t\t0.037859\n",
      "  validation loss:\t\t0.035997\n",
      "Epoch 505 of 600 took 71.011s\n",
      "  training loss:\t\t0.037833\n",
      "  validation loss:\t\t0.035903\n",
      "Epoch 506 of 600 took 71.031s\n",
      "  training loss:\t\t0.037838\n",
      "  validation loss:\t\t0.035871\n",
      "Epoch 507 of 600 took 71.011s\n",
      "  training loss:\t\t0.037799\n",
      "  validation loss:\t\t0.035958\n",
      "Epoch 508 of 600 took 70.983s\n",
      "  training loss:\t\t0.037826\n",
      "  validation loss:\t\t0.035887\n",
      "Epoch 509 of 600 took 71.075s\n",
      "  training loss:\t\t0.037810\n",
      "  validation loss:\t\t0.035912\n",
      "Epoch 510 of 600 took 71.101s\n",
      "  training loss:\t\t0.037839\n",
      "  validation loss:\t\t0.035952\n",
      "Epoch 511 of 600 took 71.000s\n",
      "  training loss:\t\t0.037808\n",
      "  validation loss:\t\t0.035806\n",
      "Epoch 512 of 600 took 71.022s\n",
      "  training loss:\t\t0.037809\n",
      "  validation loss:\t\t0.035993\n",
      "Epoch 513 of 600 took 71.004s\n",
      "  training loss:\t\t0.037786\n",
      "  validation loss:\t\t0.035903\n",
      "Epoch 514 of 600 took 71.012s\n",
      "  training loss:\t\t0.037807\n",
      "  validation loss:\t\t0.035962\n",
      "Epoch 515 of 600 took 71.092s\n",
      "  training loss:\t\t0.037784\n",
      "  validation loss:\t\t0.035920\n",
      "Epoch 516 of 600 took 71.013s\n",
      "  training loss:\t\t0.037796\n",
      "  validation loss:\t\t0.035973\n",
      "Epoch 517 of 600 took 70.982s\n",
      "  training loss:\t\t0.037780\n",
      "  validation loss:\t\t0.035835\n",
      "Epoch 518 of 600 took 70.985s\n",
      "  training loss:\t\t0.037778\n",
      "  validation loss:\t\t0.035787\n",
      "Epoch 519 of 600 took 71.012s\n",
      "  training loss:\t\t0.037809\n",
      "  validation loss:\t\t0.035835\n",
      "Epoch 520 of 600 took 70.991s\n",
      "  training loss:\t\t0.037808\n",
      "  validation loss:\t\t0.035773\n",
      "Epoch 521 of 600 took 71.016s\n",
      "  training loss:\t\t0.037788\n",
      "  validation loss:\t\t0.035815\n",
      "Epoch 522 of 600 took 71.004s\n",
      "  training loss:\t\t0.037755\n",
      "  validation loss:\t\t0.035918\n",
      "Epoch 523 of 600 took 70.980s\n",
      "  training loss:\t\t0.037760\n",
      "  validation loss:\t\t0.035998\n",
      "Epoch 524 of 600 took 70.997s\n",
      "  training loss:\t\t0.037775\n",
      "  validation loss:\t\t0.036109\n",
      "Epoch 525 of 600 took 70.991s\n",
      "  training loss:\t\t0.037745\n",
      "  validation loss:\t\t0.035899\n",
      "Epoch 526 of 600 took 71.095s\n",
      "  training loss:\t\t0.037754\n",
      "  validation loss:\t\t0.036024\n",
      "Epoch 527 of 600 took 71.022s\n",
      "  training loss:\t\t0.037771\n",
      "  validation loss:\t\t0.035844\n",
      "Epoch 528 of 600 took 70.991s\n",
      "  training loss:\t\t0.037755\n",
      "  validation loss:\t\t0.035723\n",
      "Epoch 529 of 600 took 70.994s\n",
      "  training loss:\t\t0.037783\n",
      "  validation loss:\t\t0.035947\n",
      "Epoch 530 of 600 took 70.982s\n",
      "  training loss:\t\t0.037759\n",
      "  validation loss:\t\t0.036018\n",
      "Epoch 531 of 600 took 70.988s\n",
      "  training loss:\t\t0.037780\n",
      "  validation loss:\t\t0.035878\n",
      "Epoch 532 of 600 took 71.046s\n",
      "  training loss:\t\t0.037763\n",
      "  validation loss:\t\t0.035855\n",
      "Epoch 533 of 600 took 71.064s\n",
      "  training loss:\t\t0.037767\n",
      "  validation loss:\t\t0.035818\n",
      "Epoch 534 of 600 took 71.003s\n",
      "  training loss:\t\t0.037756\n",
      "  validation loss:\t\t0.035873\n",
      "Epoch 535 of 600 took 70.983s\n",
      "  training loss:\t\t0.037735\n",
      "  validation loss:\t\t0.035988\n",
      "Epoch 536 of 600 took 71.035s\n",
      "  training loss:\t\t0.037739\n",
      "  validation loss:\t\t0.035805\n",
      "Epoch 537 of 600 took 70.992s\n",
      "  training loss:\t\t0.037733\n",
      "  validation loss:\t\t0.035945\n",
      "Epoch 538 of 600 took 71.024s\n",
      "  training loss:\t\t0.037725\n",
      "  validation loss:\t\t0.035891\n",
      "Epoch 539 of 600 took 71.012s\n",
      "  training loss:\t\t0.037717\n",
      "  validation loss:\t\t0.035740\n",
      "Epoch 540 of 600 took 71.012s\n",
      "  training loss:\t\t0.037727\n",
      "  validation loss:\t\t0.035880\n",
      "Epoch 541 of 600 took 70.980s\n",
      "  training loss:\t\t0.037731\n",
      "  validation loss:\t\t0.035902\n",
      "Epoch 542 of 600 took 71.018s\n",
      "  training loss:\t\t0.037749\n",
      "  validation loss:\t\t0.035917\n",
      "Epoch 543 of 600 took 71.035s\n",
      "  training loss:\t\t0.037743\n",
      "  validation loss:\t\t0.035938\n",
      "Epoch 544 of 600 took 71.045s\n",
      "  training loss:\t\t0.037731\n",
      "  validation loss:\t\t0.035983\n",
      "Epoch 545 of 600 took 71.003s\n",
      "  training loss:\t\t0.037733\n",
      "  validation loss:\t\t0.035762\n",
      "Epoch 546 of 600 took 71.034s\n",
      "  training loss:\t\t0.037720\n",
      "  validation loss:\t\t0.035983\n",
      "Epoch 547 of 600 took 71.004s\n",
      "  training loss:\t\t0.037743\n",
      "  validation loss:\t\t0.035802\n",
      "Epoch 548 of 600 took 71.103s\n",
      "  training loss:\t\t0.037719\n",
      "  validation loss:\t\t0.035987\n",
      "Epoch 549 of 600 took 71.034s\n",
      "  training loss:\t\t0.037722\n",
      "  validation loss:\t\t0.035783\n",
      "Epoch 550 of 600 took 71.073s\n",
      "  training loss:\t\t0.037690\n",
      "  validation loss:\t\t0.035892\n",
      "Epoch 551 of 600 took 71.049s\n",
      "  training loss:\t\t0.037714\n",
      "  validation loss:\t\t0.035816\n",
      "Epoch 552 of 600 took 71.045s\n",
      "  training loss:\t\t0.037695\n",
      "  validation loss:\t\t0.035897\n",
      "Epoch 553 of 600 took 71.015s\n",
      "  training loss:\t\t0.037696\n",
      "  validation loss:\t\t0.035857\n",
      "Epoch 554 of 600 took 71.042s\n",
      "  training loss:\t\t0.037695\n",
      "  validation loss:\t\t0.035804\n",
      "Epoch 555 of 600 took 71.005s\n",
      "  training loss:\t\t0.037677\n",
      "  validation loss:\t\t0.035860\n",
      "Epoch 556 of 600 took 71.023s\n",
      "  training loss:\t\t0.037678\n",
      "  validation loss:\t\t0.035944\n",
      "Epoch 557 of 600 took 71.017s\n",
      "  training loss:\t\t0.037695\n",
      "  validation loss:\t\t0.035883\n",
      "Epoch 558 of 600 took 71.030s\n",
      "  training loss:\t\t0.037684\n",
      "  validation loss:\t\t0.035765\n",
      "Epoch 559 of 600 took 71.012s\n",
      "  training loss:\t\t0.037693\n",
      "  validation loss:\t\t0.035979\n",
      "Epoch 560 of 600 took 71.012s\n",
      "  training loss:\t\t0.037674\n",
      "  validation loss:\t\t0.035838\n",
      "Epoch 561 of 600 took 71.038s\n",
      "  training loss:\t\t0.037684\n",
      "  validation loss:\t\t0.035774\n",
      "Epoch 562 of 600 took 71.052s\n",
      "  training loss:\t\t0.037682\n",
      "  validation loss:\t\t0.035797\n",
      "Epoch 563 of 600 took 71.033s\n",
      "  training loss:\t\t0.037670\n",
      "  validation loss:\t\t0.035802\n",
      "Epoch 564 of 600 took 70.978s\n",
      "  training loss:\t\t0.037675\n",
      "  validation loss:\t\t0.035816\n",
      "Epoch 565 of 600 took 71.051s\n",
      "  training loss:\t\t0.037686\n",
      "  validation loss:\t\t0.035841\n",
      "Epoch 566 of 600 took 71.011s\n",
      "  training loss:\t\t0.037667\n",
      "  validation loss:\t\t0.035839\n",
      "Epoch 567 of 600 took 70.987s\n",
      "  training loss:\t\t0.037642\n",
      "  validation loss:\t\t0.035983\n",
      "Epoch 568 of 600 took 70.995s\n",
      "  training loss:\t\t0.037653\n",
      "  validation loss:\t\t0.035850\n",
      "Epoch 569 of 600 took 70.981s\n",
      "  training loss:\t\t0.037671\n",
      "  validation loss:\t\t0.035841\n",
      "Epoch 570 of 600 took 71.005s\n",
      "  training loss:\t\t0.037665\n",
      "  validation loss:\t\t0.035882\n",
      "Epoch 571 of 600 took 71.023s\n",
      "  training loss:\t\t0.037638\n",
      "  validation loss:\t\t0.035930\n",
      "Epoch 572 of 600 took 71.004s\n",
      "  training loss:\t\t0.037656\n",
      "  validation loss:\t\t0.035839\n",
      "Epoch 573 of 600 took 71.015s\n",
      "  training loss:\t\t0.037651\n",
      "  validation loss:\t\t0.035821\n",
      "Epoch 574 of 600 took 71.010s\n",
      "  training loss:\t\t0.037628\n",
      "  validation loss:\t\t0.035845\n",
      "Epoch 575 of 600 took 71.024s\n",
      "  training loss:\t\t0.037622\n",
      "  validation loss:\t\t0.035737\n",
      "Epoch 576 of 600 took 71.000s\n",
      "  training loss:\t\t0.037631\n",
      "  validation loss:\t\t0.035830\n",
      "Epoch 577 of 600 took 71.022s\n",
      "  training loss:\t\t0.037627\n",
      "  validation loss:\t\t0.035780\n",
      "Epoch 578 of 600 took 71.037s\n",
      "  training loss:\t\t0.037636\n",
      "  validation loss:\t\t0.035719\n",
      "Epoch 579 of 600 took 70.998s\n",
      "  training loss:\t\t0.037633\n",
      "  validation loss:\t\t0.035987\n",
      "Epoch 580 of 600 took 71.023s\n",
      "  training loss:\t\t0.037644\n",
      "  validation loss:\t\t0.035864\n",
      "Epoch 581 of 600 took 71.021s\n",
      "  training loss:\t\t0.037626\n",
      "  validation loss:\t\t0.035970\n",
      "Epoch 582 of 600 took 71.009s\n",
      "  training loss:\t\t0.037615\n",
      "  validation loss:\t\t0.035838\n",
      "Epoch 583 of 600 took 71.032s\n",
      "  training loss:\t\t0.037601\n",
      "  validation loss:\t\t0.035892\n",
      "Epoch 584 of 600 took 70.985s\n",
      "  training loss:\t\t0.037615\n",
      "  validation loss:\t\t0.035809\n",
      "Epoch 585 of 600 took 71.045s\n",
      "  training loss:\t\t0.037610\n",
      "  validation loss:\t\t0.035848\n",
      "Epoch 586 of 600 took 71.026s\n",
      "  training loss:\t\t0.037626\n",
      "  validation loss:\t\t0.035867\n",
      "Epoch 587 of 600 took 71.087s\n",
      "  training loss:\t\t0.037614\n",
      "  validation loss:\t\t0.035890\n",
      "Epoch 588 of 600 took 71.024s\n",
      "  training loss:\t\t0.037613\n",
      "  validation loss:\t\t0.035889\n",
      "Epoch 589 of 600 took 71.030s\n",
      "  training loss:\t\t0.037594\n",
      "  validation loss:\t\t0.035921\n",
      "Epoch 590 of 600 took 71.076s\n",
      "  training loss:\t\t0.037605\n",
      "  validation loss:\t\t0.035964\n",
      "Epoch 591 of 600 took 71.071s\n",
      "  training loss:\t\t0.037589\n",
      "  validation loss:\t\t0.035917\n",
      "Epoch 592 of 600 took 71.031s\n",
      "  training loss:\t\t0.037582\n",
      "  validation loss:\t\t0.035765\n",
      "Epoch 593 of 600 took 71.022s\n",
      "  training loss:\t\t0.037620\n",
      "  validation loss:\t\t0.035773\n",
      "Epoch 594 of 600 took 70.995s\n",
      "  training loss:\t\t0.037604\n",
      "  validation loss:\t\t0.035769\n",
      "Epoch 595 of 600 took 71.035s\n",
      "  training loss:\t\t0.037578\n",
      "  validation loss:\t\t0.035740\n",
      "Epoch 596 of 600 took 70.982s\n",
      "  training loss:\t\t0.037580\n",
      "  validation loss:\t\t0.035872\n",
      "Epoch 597 of 600 took 71.018s\n",
      "  training loss:\t\t0.037573\n",
      "  validation loss:\t\t0.035773\n",
      "Epoch 598 of 600 took 71.020s\n",
      "  training loss:\t\t0.037587\n",
      "  validation loss:\t\t0.035882\n",
      "Epoch 599 of 600 took 71.032s\n",
      "  training loss:\t\t0.037566\n",
      "  validation loss:\t\t0.035772\n",
      "Epoch 600 of 600 took 71.066s\n",
      "  training loss:\t\t0.037568\n",
      "  validation loss:\t\t0.035744\n",
      "Final results:\n",
      "  test loss:\t\t\t0.035500\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18241571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18241571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 50 of 50 took 199.469s\n",
    "  training loss:\t\t0.035236\n",
    "  validation loss:\t\t0.034971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}