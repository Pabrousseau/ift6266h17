{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 750 Ti (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "#import lasagne.layers.dnn\n",
    "\n",
    "import Cae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def im2ar(x):\n",
    "    y = [[[0]*len(x)]*len(x)]*3\n",
    "    y[0] = x[:,:,0]\n",
    "    y[1] = x[:,:,1]\n",
    "    y[2] = x[:,:,2]\n",
    "    return y\n",
    "\n",
    "def ar2im(x):\n",
    "    y = [[[0]*3]*len(x)]*len(x)\n",
    "    y[:,:,0] = x[0,:,:] \n",
    "    y[:,:,1] = x[1,:,:]\n",
    "    y[:,:,2] = x[2,:,:]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_dataset_mscoco():\n",
    "    #Path\n",
    "    mscoco=\"/home/myuser/Documents/Lasagne/inpainting\"\n",
    "    split=\"train2014\"\n",
    "    data_path = os.path.join(mscoco, split)\n",
    "    imgs = glob.glob(data_path + \"/*.jpg\")\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "            \n",
    "    for i, img_path in enumerate(imgs):\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.divide(np.array(img,dtype='float32'),255)\n",
    "\n",
    "        if len(img_array.shape) == 3:\n",
    "            temp = np.copy(img_array)\n",
    "            input = np.copy(img_array)\n",
    "            input[16:48, 16:48,:] = 0\n",
    "            target = img_array[16:48, 16:48,:]\n",
    "        else:\n",
    "            input[:,:,0] = np.copy(img_array)\n",
    "            input[:,:,1] = np.copy(img_array)\n",
    "            input[:,:,2] = np.copy(img_array)\n",
    "            target = input[16:48, 16:48,:]\n",
    "            input[16:48, 16:48,:] = 0\n",
    "        \n",
    "        X_train.append(im2ar(input))\n",
    "        y_train.append(im2ar(target))\n",
    "    \n",
    "    split=\"val2014\"\n",
    "    data_path = os.path.join(mscoco, split)\n",
    "    imgs = glob.glob(data_path + \"/*.jpg\")\n",
    "    \n",
    "    X_val = []\n",
    "    y_val = []\n",
    "            \n",
    "    for i, img_path in enumerate(imgs):\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.divide(np.array(img,dtype='float32'),255)\n",
    "\n",
    "        if len(img_array.shape) == 3:\n",
    "            input = np.copy(img_array)\n",
    "            input[16:48, 16:48,:] = 0\n",
    "            target = img_array[16:48, 16:48,:]\n",
    "        else:\n",
    "            input[:,:,0] = np.copy(img_array)\n",
    "            input[:,:,1] = np.copy(img_array)\n",
    "            input[:,:,2] = np.copy(img_array)\n",
    "            target = input[16:48, 16:48,:]\n",
    "            input[16:48, 16:48,:] = 0\n",
    "        \n",
    "        X_val.append(im2ar(input))\n",
    "        y_val.append(im2ar(target))\n",
    "    \n",
    "    # We reserve the last 10000 training examples for testing.\n",
    "    X_val, X_test = X_val[:-10000], X_val[-10000:]\n",
    "    y_val, y_test = y_val[:-10000], y_val[-10000:]\n",
    "    \n",
    "    return (np.array(X_train),np.array(y_train),np.array(X_val),np.array(y_val),np.array(X_test),np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Batch iterator\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "def main():\n",
    "    \n",
    "    # Hyper Params\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.975\n",
    "    batchsize = 200\n",
    "    \n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_dataset_mscoco()\n",
    "    \n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    inputVar = T.tensor4('inputs')\n",
    "    target_var = T.tensor4('targets')\n",
    "\n",
    "    # Build Network\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    network = Cae.build(inputVar)\n",
    "\n",
    "    # Training Loss expression\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    # Add regularization lasagne.regularization.\n",
    "\n",
    "    # Update expressions \n",
    "    # Stochastic Gradient Descent (SGD) with Nesterov momentum\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate, momentum)\n",
    "\n",
    "    # Test Loss expression\n",
    "    # 'Deterministic = True' disables droupout\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.squared_error(test_prediction,target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "\n",
    "    # Train Function\n",
    "    train_fn = theano.function([inputVar, target_var], loss, updates=updates)\n",
    "\n",
    "    # Test Function\n",
    "    val_fn = theano.function([inputVar, target_var], test_loss)\n",
    "    # Training Loop\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batchsize, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # Full pass over the validation data\n",
    "        val_err = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, batchsize, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_batches += 1\n",
    "\n",
    "        # Print the results for this epoch\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "\n",
    "    # Print the test error\n",
    "    test_err = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, batchsize, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "\n",
    "\n",
    "    # Save model\n",
    "    np.savez('cae-100e.npz', *lasagne.layers.get_all_param_values(network))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 100 took 193.952s\n",
      "  training loss:\t\t0.071211\n",
      "  validation loss:\t\t0.065530\n",
      "Epoch 2 of 100 took 193.797s\n",
      "  training loss:\t\t0.059697\n",
      "  validation loss:\t\t0.051746\n",
      "Epoch 3 of 100 took 193.802s\n",
      "  training loss:\t\t0.048448\n",
      "  validation loss:\t\t0.046077\n",
      "Epoch 4 of 100 took 193.854s\n",
      "  training loss:\t\t0.044976\n",
      "  validation loss:\t\t0.043772\n",
      "Epoch 5 of 100 took 194.131s\n",
      "  training loss:\t\t0.043242\n",
      "  validation loss:\t\t0.042396\n",
      "Epoch 6 of 100 took 194.359s\n",
      "  training loss:\t\t0.042113\n",
      "  validation loss:\t\t0.041624\n",
      "Epoch 7 of 100 took 193.890s\n",
      "  training loss:\t\t0.041356\n",
      "  validation loss:\t\t0.040935\n",
      "Epoch 8 of 100 took 193.850s\n",
      "  training loss:\t\t0.040816\n",
      "  validation loss:\t\t0.040460\n",
      "Epoch 9 of 100 took 196.376s\n",
      "  training loss:\t\t0.040387\n",
      "  validation loss:\t\t0.040091\n",
      "Epoch 10 of 100 took 194.938s\n",
      "  training loss:\t\t0.040018\n",
      "  validation loss:\t\t0.039755\n",
      "Epoch 11 of 100 took 194.022s\n",
      "  training loss:\t\t0.039579\n",
      "  validation loss:\t\t0.039332\n",
      "Epoch 12 of 100 took 193.866s\n",
      "  training loss:\t\t0.038581\n",
      "  validation loss:\t\t0.037892\n",
      "Epoch 13 of 100 took 193.852s\n",
      "  training loss:\t\t0.037694\n",
      "  validation loss:\t\t0.037383\n",
      "Epoch 14 of 100 took 193.846s\n",
      "  training loss:\t\t0.037241\n",
      "  validation loss:\t\t0.036975\n",
      "Epoch 15 of 100 took 193.813s\n",
      "  training loss:\t\t0.036936\n",
      "  validation loss:\t\t0.036737\n",
      "Epoch 16 of 100 took 194.176s\n",
      "  training loss:\t\t0.036676\n",
      "  validation loss:\t\t0.036644\n",
      "Epoch 17 of 100 took 193.973s\n",
      "  training loss:\t\t0.036474\n",
      "  validation loss:\t\t0.036325\n",
      "Epoch 18 of 100 took 193.905s\n",
      "  training loss:\t\t0.036301\n",
      "  validation loss:\t\t0.036296\n",
      "Epoch 19 of 100 took 193.835s\n",
      "  training loss:\t\t0.036136\n",
      "  validation loss:\t\t0.036036\n",
      "Epoch 20 of 100 took 193.856s\n",
      "  training loss:\t\t0.035983\n",
      "  validation loss:\t\t0.035915\n",
      "Epoch 21 of 100 took 195.323s\n",
      "  training loss:\t\t0.035853\n",
      "  validation loss:\t\t0.036067\n",
      "Epoch 22 of 100 took 194.639s\n",
      "  training loss:\t\t0.035742\n",
      "  validation loss:\t\t0.035780\n",
      "Epoch 23 of 100 took 193.860s\n",
      "  training loss:\t\t0.035620\n",
      "  validation loss:\t\t0.035690\n",
      "Epoch 24 of 100 took 194.059s\n",
      "  training loss:\t\t0.035541\n",
      "  validation loss:\t\t0.035592\n",
      "Epoch 25 of 100 took 193.857s\n",
      "  training loss:\t\t0.035430\n",
      "  validation loss:\t\t0.035605\n",
      "Epoch 26 of 100 took 193.856s\n",
      "  training loss:\t\t0.035333\n",
      "  validation loss:\t\t0.035695\n",
      "Epoch 27 of 100 took 193.836s\n",
      "  training loss:\t\t0.035260\n",
      "  validation loss:\t\t0.035448\n",
      "Epoch 28 of 100 took 193.809s\n",
      "  training loss:\t\t0.035156\n",
      "  validation loss:\t\t0.035426\n",
      "Epoch 29 of 100 took 193.803s\n",
      "  training loss:\t\t0.035084\n",
      "  validation loss:\t\t0.035308\n",
      "Epoch 30 of 100 took 193.906s\n",
      "  training loss:\t\t0.034995\n",
      "  validation loss:\t\t0.035572\n",
      "Epoch 31 of 100 took 193.885s\n",
      "  training loss:\t\t0.034929\n",
      "  validation loss:\t\t0.035219\n",
      "Epoch 32 of 100 took 193.885s\n",
      "  training loss:\t\t0.034853\n",
      "  validation loss:\t\t0.035207\n",
      "Epoch 33 of 100 took 193.897s\n",
      "  training loss:\t\t0.034788\n",
      "  validation loss:\t\t0.035103\n",
      "Epoch 34 of 100 took 193.799s\n",
      "  training loss:\t\t0.034697\n",
      "  validation loss:\t\t0.035244\n",
      "Epoch 35 of 100 took 193.804s\n",
      "  training loss:\t\t0.034648\n",
      "  validation loss:\t\t0.035053\n",
      "Epoch 36 of 100 took 193.863s\n",
      "  training loss:\t\t0.034573\n",
      "  validation loss:\t\t0.034994\n",
      "Epoch 37 of 100 took 193.870s\n",
      "  training loss:\t\t0.034501\n",
      "  validation loss:\t\t0.035028\n",
      "Epoch 38 of 100 took 193.887s\n",
      "  training loss:\t\t0.034445\n",
      "  validation loss:\t\t0.034907\n",
      "Epoch 39 of 100 took 193.802s\n",
      "  training loss:\t\t0.034410\n",
      "  validation loss:\t\t0.034924\n",
      "Epoch 40 of 100 took 193.883s\n",
      "  training loss:\t\t0.034335\n",
      "  validation loss:\t\t0.034892\n",
      "Epoch 41 of 100 took 193.832s\n",
      "  training loss:\t\t0.034267\n",
      "  validation loss:\t\t0.034937\n",
      "Epoch 42 of 100 took 193.907s\n",
      "  training loss:\t\t0.034205\n",
      "  validation loss:\t\t0.034848\n",
      "Epoch 43 of 100 took 193.864s\n",
      "  training loss:\t\t0.034169\n",
      "  validation loss:\t\t0.034820\n",
      "Epoch 44 of 100 took 193.819s\n",
      "  training loss:\t\t0.034109\n",
      "  validation loss:\t\t0.034772\n",
      "Epoch 45 of 100 took 193.874s\n",
      "  training loss:\t\t0.034050\n",
      "  validation loss:\t\t0.034907\n",
      "Epoch 46 of 100 took 193.844s\n",
      "  training loss:\t\t0.034006\n",
      "  validation loss:\t\t0.034715\n",
      "Epoch 47 of 100 took 194.255s\n",
      "  training loss:\t\t0.033944\n",
      "  validation loss:\t\t0.034743\n",
      "Epoch 48 of 100 took 194.082s\n",
      "  training loss:\t\t0.033884\n",
      "  validation loss:\t\t0.034652\n",
      "Epoch 49 of 100 took 193.900s\n",
      "  training loss:\t\t0.033835\n",
      "  validation loss:\t\t0.034633\n",
      "Epoch 50 of 100 took 193.837s\n",
      "  training loss:\t\t0.033765\n",
      "  validation loss:\t\t0.034672\n",
      "Epoch 51 of 100 took 193.808s\n",
      "  training loss:\t\t0.033747\n",
      "  validation loss:\t\t0.034633\n",
      "Epoch 52 of 100 took 193.867s\n",
      "  training loss:\t\t0.033679\n",
      "  validation loss:\t\t0.034644\n",
      "Epoch 53 of 100 took 193.860s\n",
      "  training loss:\t\t0.033610\n",
      "  validation loss:\t\t0.034632\n",
      "Epoch 54 of 100 took 193.837s\n",
      "  training loss:\t\t0.033585\n",
      "  validation loss:\t\t0.034677\n",
      "Epoch 55 of 100 took 194.137s\n",
      "  training loss:\t\t0.033524\n",
      "  validation loss:\t\t0.034817\n",
      "Epoch 56 of 100 took 193.805s\n",
      "  training loss:\t\t0.033453\n",
      "  validation loss:\t\t0.034689\n",
      "Epoch 57 of 100 took 194.153s\n",
      "  training loss:\t\t0.033402\n",
      "  validation loss:\t\t0.034586\n",
      "Epoch 58 of 100 took 193.788s\n",
      "  training loss:\t\t0.033374\n",
      "  validation loss:\t\t0.034576\n",
      "Epoch 59 of 100 took 194.641s\n",
      "  training loss:\t\t0.033303\n",
      "  validation loss:\t\t0.034589\n",
      "Epoch 60 of 100 took 193.791s\n",
      "  training loss:\t\t0.033233\n",
      "  validation loss:\t\t0.034689\n",
      "Epoch 61 of 100 took 193.860s\n",
      "  training loss:\t\t0.033201\n",
      "  validation loss:\t\t0.034703\n",
      "Epoch 62 of 100 took 193.808s\n",
      "  training loss:\t\t0.033151\n",
      "  validation loss:\t\t0.034632\n",
      "Epoch 63 of 100 took 193.897s\n",
      "  training loss:\t\t0.033126\n",
      "  validation loss:\t\t0.034726\n",
      "Epoch 64 of 100 took 193.807s\n",
      "  training loss:\t\t0.033043\n",
      "  validation loss:\t\t0.034642\n",
      "Epoch 65 of 100 took 193.846s\n",
      "  training loss:\t\t0.032993\n",
      "  validation loss:\t\t0.034618\n",
      "Epoch 66 of 100 took 193.844s\n",
      "  training loss:\t\t0.032937\n",
      "  validation loss:\t\t0.034640\n",
      "Epoch 67 of 100 took 193.890s\n",
      "  training loss:\t\t0.032888\n",
      "  validation loss:\t\t0.034715\n",
      "Epoch 68 of 100 took 194.217s\n",
      "  training loss:\t\t0.032814\n",
      "  validation loss:\t\t0.034764\n",
      "Epoch 69 of 100 took 194.544s\n",
      "  training loss:\t\t0.032776\n",
      "  validation loss:\t\t0.034645\n",
      "Epoch 70 of 100 took 193.871s\n",
      "  training loss:\t\t0.032709\n",
      "  validation loss:\t\t0.034653\n",
      "Epoch 71 of 100 took 193.915s\n",
      "  training loss:\t\t0.032669\n",
      "  validation loss:\t\t0.034796\n",
      "Epoch 72 of 100 took 193.799s\n",
      "  training loss:\t\t0.032602\n",
      "  validation loss:\t\t0.034900\n",
      "Epoch 73 of 100 took 193.906s\n",
      "  training loss:\t\t0.032539\n",
      "  validation loss:\t\t0.034776\n",
      "Epoch 74 of 100 took 193.963s\n",
      "  training loss:\t\t0.032519\n",
      "  validation loss:\t\t0.034953\n",
      "Epoch 75 of 100 took 193.805s\n",
      "  training loss:\t\t0.032454\n",
      "  validation loss:\t\t0.034733\n",
      "Epoch 76 of 100 took 193.846s\n",
      "  training loss:\t\t0.032374\n",
      "  validation loss:\t\t0.034759\n",
      "Epoch 77 of 100 took 193.861s\n",
      "  training loss:\t\t0.032324\n",
      "  validation loss:\t\t0.034797\n",
      "Epoch 78 of 100 took 193.851s\n",
      "  training loss:\t\t0.032283\n",
      "  validation loss:\t\t0.034780\n",
      "Epoch 79 of 100 took 193.854s\n",
      "  training loss:\t\t0.032202\n",
      "  validation loss:\t\t0.034867\n",
      "Epoch 80 of 100 took 193.800s\n",
      "  training loss:\t\t0.032154\n",
      "  validation loss:\t\t0.035065\n",
      "Epoch 81 of 100 took 193.871s\n",
      "  training loss:\t\t0.032118\n",
      "  validation loss:\t\t0.034938\n",
      "Epoch 82 of 100 took 193.782s\n",
      "  training loss:\t\t0.032037\n",
      "  validation loss:\t\t0.035416\n",
      "Epoch 83 of 100 took 193.810s\n",
      "  training loss:\t\t0.031960\n",
      "  validation loss:\t\t0.034930\n",
      "Epoch 84 of 100 took 193.811s\n",
      "  training loss:\t\t0.031935\n",
      "  validation loss:\t\t0.034977\n",
      "Epoch 85 of 100 took 194.205s\n",
      "  training loss:\t\t0.031867\n",
      "  validation loss:\t\t0.035284\n",
      "Epoch 86 of 100 took 193.882s\n",
      "  training loss:\t\t0.031812\n",
      "  validation loss:\t\t0.034981\n",
      "Epoch 87 of 100 took 193.965s\n",
      "  training loss:\t\t0.031706\n",
      "  validation loss:\t\t0.035391\n",
      "Epoch 88 of 100 took 193.812s\n",
      "  training loss:\t\t0.031699\n",
      "  validation loss:\t\t0.035161\n",
      "Epoch 89 of 100 took 193.829s\n",
      "  training loss:\t\t0.031667\n",
      "  validation loss:\t\t0.035295\n",
      "Epoch 90 of 100 took 194.194s\n",
      "  training loss:\t\t0.031565\n",
      "  validation loss:\t\t0.035155\n",
      "Epoch 91 of 100 took 193.965s\n",
      "  training loss:\t\t0.031513\n",
      "  validation loss:\t\t0.035370\n",
      "Epoch 92 of 100 took 193.839s\n",
      "  training loss:\t\t0.031440\n",
      "  validation loss:\t\t0.035225\n",
      "Epoch 93 of 100 took 193.860s\n",
      "  training loss:\t\t0.031376\n",
      "  validation loss:\t\t0.035165\n",
      "Epoch 94 of 100 took 193.802s\n",
      "  training loss:\t\t0.031303\n",
      "  validation loss:\t\t0.035241\n",
      "Epoch 95 of 100 took 193.860s\n",
      "  training loss:\t\t0.031259\n",
      "  validation loss:\t\t0.035314\n",
      "Epoch 96 of 100 took 193.844s\n",
      "  training loss:\t\t0.031201\n",
      "  validation loss:\t\t0.035229\n",
      "Epoch 97 of 100 took 194.080s\n",
      "  training loss:\t\t0.031116\n",
      "  validation loss:\t\t0.035249\n",
      "Epoch 98 of 100 took 193.915s\n",
      "  training loss:\t\t0.031075\n",
      "  validation loss:\t\t0.035579\n",
      "Epoch 99 of 100 took 194.268s\n",
      "  training loss:\t\t0.031054\n",
      "  validation loss:\t\t0.035293\n",
      "Epoch 100 of 100 took 193.977s\n",
      "  training loss:\t\t0.030957\n",
      "  validation loss:\t\t0.035663\n",
      "Final results:\n",
      "  test loss:\t\t\t0.035444\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
